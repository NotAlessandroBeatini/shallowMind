{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0109a1",
   "metadata": {},
   "source": [
    "# Test multinode multigpu training with deepspeed and ray\n",
    "\n",
    "Tokenized datasets are cached under `data/main_cache`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9be1cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 18:51:25,544\tINFO worker.py:1694 -- Connecting to existing Ray cluster at address: 10.141.1.24:6379...\n",
      "2025-06-26 18:51:25,565\tINFO worker.py:1879 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m10.141.1.24:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAy already up and running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainTrainable pid=4118901)\u001b[0m 2025-06-26 18:51:46,806 - WARNING - Rewritten PROJECT_ROOT path to: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(TrainTrainable pid=4118901)\u001b[0m 2025-06-26 18:51:46,806 - INFO - Determined Project Root: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(TrainTrainable pid=4118901)\u001b[0m 2025-06-26 18:51:49,704 - INFO - PyTorch version 2.5.1+cu121 available.\n",
      "\u001b[36m(TrainTrainable pid=4118901)\u001b[0m 2025-06-26 18:51:50,011 - INFO - Registering dataset: wikitext\n",
      "\u001b[36m(TrainTrainable pid=4118901)\u001b[0m 2025-06-26 18:51:50,011 - INFO - Registering dataset: oscar\n",
      "\u001b[36m(TrainTrainable pid=4118901)\u001b[0m 2025-06-26 18:51:50,012 - INFO - Registering dataset: bookcorpus\n",
      "\u001b[36m(TrainTrainable pid=4118901)\u001b[0m 2025-06-26 18:51:50,012 - INFO - Registering dataset: openwebtext\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[36m(TorchTrainer pid=4118901)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=4118901)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4119555) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=4118901)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4119551) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=4118901)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4119552) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=4118901)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4119553) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=4118901)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=242452) world_rank=4, local_rank=0, node_rank=1\n",
      "\u001b[36m(TorchTrainer pid=4118901)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=242454) world_rank=5, local_rank=1, node_rank=1\n",
      "\u001b[36m(TorchTrainer pid=4118901)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=242453) world_rank=6, local_rank=2, node_rank=1\n",
      "\u001b[36m(TorchTrainer pid=4118901)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=242455) world_rank=7, local_rank=3, node_rank=1\n",
      "\u001b[36m(RayTrainWorker pid=4119553)\u001b[0m 2025-06-26 18:52:00,769 - WARNING - Rewritten PROJECT_ROOT path to: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(RayTrainWorker pid=4119553)\u001b[0m 2025-06-26 18:52:00,769 - INFO - Determined Project Root: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(RayTrainWorker pid=4119553)\u001b[0m 2025-06-26 18:52:03,956 - INFO - PyTorch version 2.5.1+cu121 available.\n",
      "\u001b[36m(RayTrainWorker pid=4119553)\u001b[0m 2025-06-26 18:52:04,281 - INFO - Registering dataset: wikitext\n",
      "\u001b[36m(RayTrainWorker pid=4119553)\u001b[0m 2025-06-26 18:52:04,281 - INFO - Registering dataset: oscar\n",
      "\u001b[36m(RayTrainWorker pid=4119553)\u001b[0m 2025-06-26 18:52:04,282 - INFO - Registering dataset: bookcorpus\n",
      "\u001b[36m(RayTrainWorker pid=4119553)\u001b[0m 2025-06-26 18:52:04,282 - INFO - Registering dataset: openwebtext\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:05,155 - INFO - Relative cache_dir provided. Resolved to: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:05,157 - INFO - DataModule initialized.\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:05,157 - INFO -   Raw cache: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:05,157 - INFO -   Tokenized cache base for 'gpt2': /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:05,157 - WARNING - Tokenizer does not have a pad token. Setting pad_token = eos_token.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m [2025-06-26 18:52:05,617] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=242453, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:00,835 - WARNING - Rewritten PROJECT_ROOT path to: /davinci-1/home/abeatini/pycharmProjects/shallowMind\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=242453, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:00,835 - INFO - Determined Project Root: /davinci-1/home/abeatini/pycharmProjects/shallowMind\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/ray/train/lightning/_lightning_utils.py:262: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m `get_trial_name` is deprecated because the concept of a `Trial` will soon be removed in Ray Train.Ray Train will no longer assume that it's running within a Ray Tune `Trial` in the future. See this issue for more context and migration options: https://github.com/ray-project/ray/issues/49454. Disable these warnings by setting the environment variable: RAY_TRAIN_ENABLE_V2_MIGRATION_WARNINGS=0\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:07,601 - INFO - You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:07,624 - INFO - GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:07,624 - INFO - TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:07,624 - INFO - HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:07,628 - INFO - You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:07,628 - INFO - initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "\u001b[36m(RayTrainWorker pid=242453, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:04,244 - INFO - PyTorch version 2.5.1+cu121 available.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:09,561 - INFO - --- Starting prepare_data (runs only on rank 0) ---\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:09,561 - INFO - Using Raw cache directory: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:09,561 - INFO - Using Tokenized cache directory (for gpt2): /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:09,561 - INFO - Preparing dataset: wikitext (Class: WikiTextDataset) with specific config: {}\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:09,561 - INFO - Processing split 'train' for wikitext (Info: {'hf_split_name': 'train', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:09,561 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'train' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=242453, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:04,606 - INFO - Registering dataset: wikitext\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=242453, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:04,606 - INFO - Registering dataset: oscar\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=242453, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:04,606 - INFO - Registering dataset: bookcorpus\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=242453, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:04,606 - INFO - Registering dataset: openwebtext\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m ************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m None\n",
      "\u001b[36m(RayTrainWorker pid=4119551)\u001b[0m [2025-06-26 18:52:07,093] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:15,979 - INFO - Raw base split 'train' loaded/verified in 6.42s. Base size: 36718 examples.\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:15,979 - INFO - No percentage slice requested or applied for 'train'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:15,979 - INFO - Raw data ready for wikitext split 'train'. Size: 36718\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:15,979 - INFO - Target tokenized path: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:15,980 - INFO - Tokenized data already exists at /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full. Skipping tokenization.\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:15,980 - INFO - Processing split 'validation' for wikitext (Info: {'hf_split_name': 'validation', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:15,980 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'validation' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4119551)\u001b[0m 2025-06-26 18:52:06,768 - INFO - Relative cache_dir provided. Resolved to: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4119551)\u001b[0m 2025-06-26 18:52:06,769 - INFO - DataModule initialized.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4119551)\u001b[0m 2025-06-26 18:52:06,769 - INFO -   Raw cache: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4119551)\u001b[0m 2025-06-26 18:52:06,769 - INFO -   Tokenized cache base for 'gpt2': /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4119551)\u001b[0m 2025-06-26 18:52:06,769 - WARNING - Tokenizer does not have a pad token. Setting pad_token = eos_token.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4119551)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/ray/train/lightning/_lightning_utils.py:262: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4119551)\u001b[0m `get_trial_name` is deprecated because the concept of a `Trial` will soon be removed in Ray Train.Ray Train will no longer assume that it's running within a Ray Tune `Trial` in the future. See this issue for more context and migration options: https://github.com/ray-project/ray/issues/49454. Disable these warnings by setting the environment variable: RAY_TRAIN_ENABLE_V2_MIGRATION_WARNINGS=0\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4119551)\u001b[0m 2025-06-26 18:52:08,993 - INFO - initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/8\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:09,561 - INFO - --- Starting prepare_data (runs only on rank 0) ---\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:09,562 - INFO - Using Raw cache directory: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:09,562 - INFO - Using Tokenized cache directory (for gpt2): /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:09,562 - INFO - Preparing dataset: wikitext (Class: WikiTextDataset) with specific config: {}\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:09,562 - INFO - Processing split 'train' for wikitext (Info: {'hf_split_name': 'train', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:09,562 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'train' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:20,132 - INFO - Raw base split 'validation' loaded/verified in 4.15s. Base size: 3760 examples.\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:20,132 - INFO - No percentage slice requested or applied for 'validation'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:20,132 - INFO - Raw data ready for wikitext split 'validation'. Size: 3760\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:20,133 - INFO - Processing split 'test' for wikitext (Info: {'hf_split_name': 'test', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=242452, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:20,133 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'test' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m ************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m None\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:23,780 - INFO - Raw base split 'test' loaded/verified in 3.65s. Base size: 4358 examples.\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:23,780 - INFO - No percentage slice requested or applied for 'test'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:23,780 - INFO - Raw data ready for wikitext split 'test'. Size: 4358\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:23,781 - INFO - --- Finished prepare_data ---\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:16,208 - INFO - Raw base split 'train' loaded/verified in 6.65s. Base size: 36718 examples.\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:16,208 - INFO - No percentage slice requested or applied for 'train'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:16,208 - INFO - Raw data ready for wikitext split 'train'. Size: 36718\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:23,780 - INFO - Target tokenized path: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:23,781 - INFO - Tokenized data already exists at /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full. Skipping tokenization.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:16,208 - INFO - Processing split 'validation' for wikitext (Info: {'hf_split_name': 'validation', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=4119555)\u001b[0m 2025-06-26 18:52:16,209 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'validation' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,326 - INFO - --- Setting up data for stage: fit (runs on all ranks) ---\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,326 - INFO - Setting up dataset: wikitext (tokenizer: gpt2). Expecting splits based on: {'train': {'hf_split_name': 'train', 'percentage': None}, 'validation': {'hf_split_name': 'validation', 'percentage': None}, 'test': {'hf_split_name': 'test', 'percentage': None}}\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,326 - INFO - Attempting to load 'train' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,326 - INFO - Loading packed dataset for split 'train' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,331 - INFO - Packed dataset loaded from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full with columns ['input_ids', 'labels', 'attention_mask']\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,331 - INFO - Successfully loaded 'train' split for wikitext.\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,331 - INFO - Attempting to load 'validation' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,331 - INFO - Loading packed dataset for split 'validation' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,335 - INFO - Successfully loaded 'validation' split for wikitext.\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,335 - INFO - Setup complete for stage 'fit'. Combined datasets:\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,335 - INFO -   Train sources: 1, Total examples: 4723\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,335 - INFO -   Val sources: 1, Total examples: 488\n",
      "\u001b[36m(RayTrainWorker pid=242455, ip=10.141.1.44)\u001b[0m 2025-06-26 18:52:24,335 - INFO -   Test sources: 0, Total examples: 0\n",
      "\u001b[36m(TrainTrainable pid=4129881)\u001b[0m 2025-06-26 18:54:50,956 - WARNING - Rewritten PROJECT_ROOT path to: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(TrainTrainable pid=4129881)\u001b[0m 2025-06-26 18:54:50,956 - INFO - Determined Project Root: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(TrainTrainable pid=4129881)\u001b[0m 2025-06-26 18:54:53,885 - INFO - PyTorch version 2.5.1+cu121 available.\n",
      "\u001b[36m(TrainTrainable pid=4129881)\u001b[0m 2025-06-26 18:54:54,185 - INFO - Registering dataset: wikitext\n",
      "\u001b[36m(TrainTrainable pid=4129881)\u001b[0m 2025-06-26 18:54:54,185 - INFO - Registering dataset: oscar\n",
      "\u001b[36m(TrainTrainable pid=4129881)\u001b[0m 2025-06-26 18:54:54,185 - INFO - Registering dataset: bookcorpus\n",
      "\u001b[36m(TrainTrainable pid=4129881)\u001b[0m 2025-06-26 18:54:54,185 - INFO - Registering dataset: openwebtext\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[36m(TorchTrainer pid=4129881)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=4129881)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4130538) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=4129881)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4130541) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=4129881)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4130537) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=4129881)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4130536) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=4129881)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=243218) world_rank=4, local_rank=0, node_rank=1\n",
      "\u001b[36m(TorchTrainer pid=4129881)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=243216) world_rank=5, local_rank=1, node_rank=1\n",
      "\u001b[36m(TorchTrainer pid=4129881)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=243215) world_rank=6, local_rank=2, node_rank=1\n",
      "\u001b[36m(TorchTrainer pid=4129881)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=243217) world_rank=7, local_rank=3, node_rank=1\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:02,970 - WARNING - Rewritten PROJECT_ROOT path to: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:02,970 - INFO - Determined Project Root: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:06,060 - INFO - PyTorch version 2.5.1+cu121 available.\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:06,388 - INFO - Registering dataset: wikitext\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:06,389 - INFO - Registering dataset: oscar\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:06,389 - INFO - Registering dataset: bookcorpus\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:06,389 - INFO - Registering dataset: openwebtext\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:07,868 - INFO - Relative cache_dir provided. Resolved to: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:07,870 - INFO - DataModule initialized.\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:07,870 - INFO -   Raw cache: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:07,870 - INFO -   Tokenized cache base for 'gpt2': /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:07,870 - WARNING - Tokenizer does not have a pad token. Setting pad_token = eos_token.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m [2025-06-26 18:55:08,328] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:03,317 - WARNING - Rewritten PROJECT_ROOT path to: /davinci-1/home/abeatini/pycharmProjects/shallowMind\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:03,317 - INFO - Determined Project Root: /davinci-1/home/abeatini/pycharmProjects/shallowMind\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/ray/train/lightning/_lightning_utils.py:262: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m `get_trial_name` is deprecated because the concept of a `Trial` will soon be removed in Ray Train.Ray Train will no longer assume that it's running within a Ray Tune `Trial` in the future. See this issue for more context and migration options: https://github.com/ray-project/ray/issues/49454. Disable these warnings by setting the environment variable: RAY_TRAIN_ENABLE_V2_MIGRATION_WARNINGS=0\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:10,075 - INFO - initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:10,245 - INFO - You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:10,273 - INFO - GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:10,273 - INFO - TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:10,273 - INFO - HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:10,277 - INFO - You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:07,068 - INFO - PyTorch version 2.5.1+cu121 available.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:12,009 - INFO - --- Starting prepare_data (runs only on rank 0) ---\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:12,009 - INFO - Using Raw cache directory: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:12,009 - INFO - Using Tokenized cache directory (for gpt2): /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:12,009 - INFO - Preparing dataset: wikitext (Class: WikiTextDataset) with specific config: {}\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:12,009 - INFO - Processing split 'train' for wikitext (Info: {'hf_split_name': 'train', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:12,009 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'train' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:07,397 - INFO - Registering dataset: wikitext\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:07,398 - INFO - Registering dataset: oscar\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:07,398 - INFO - Registering dataset: bookcorpus\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:07,398 - INFO - Registering dataset: openwebtext\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m ************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m None\n",
      "\u001b[36m(RayTrainWorker pid=4130536)\u001b[0m [2025-06-26 18:55:09,516] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:18,466 - INFO - Raw base split 'train' loaded/verified in 6.46s. Base size: 36718 examples.\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:18,466 - INFO - No percentage slice requested or applied for 'train'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:18,466 - INFO - Raw data ready for wikitext split 'train'. Size: 36718\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:18,466 - INFO - Target tokenized path: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:18,466 - INFO - Tokenized data already exists at /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full. Skipping tokenization.\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:18,466 - INFO - Processing split 'validation' for wikitext (Info: {'hf_split_name': 'validation', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:18,467 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'validation' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4130536)\u001b[0m 2025-06-26 18:55:08,992 - INFO - Relative cache_dir provided. Resolved to: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4130536)\u001b[0m 2025-06-26 18:55:08,992 - INFO - DataModule initialized.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4130536)\u001b[0m 2025-06-26 18:55:08,992 - INFO -   Raw cache: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4130536)\u001b[0m 2025-06-26 18:55:08,992 - INFO -   Tokenized cache base for 'gpt2': /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4130536)\u001b[0m 2025-06-26 18:55:08,992 - WARNING - Tokenizer does not have a pad token. Setting pad_token = eos_token.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4130536)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/ray/train/lightning/_lightning_utils.py:262: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4130536)\u001b[0m `get_trial_name` is deprecated because the concept of a `Trial` will soon be removed in Ray Train.Ray Train will no longer assume that it's running within a Ray Tune `Trial` in the future. See this issue for more context and migration options: https://github.com/ray-project/ray/issues/49454. Disable these warnings by setting the environment variable: RAY_TRAIN_ENABLE_V2_MIGRATION_WARNINGS=0\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4130536)\u001b[0m 2025-06-26 18:55:11,130 - INFO - initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/8\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:12,004 - INFO - --- Starting prepare_data (runs only on rank 0) ---\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:12,005 - INFO - Using Raw cache directory: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:12,005 - INFO - Using Tokenized cache directory (for gpt2): /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:12,005 - INFO - Preparing dataset: wikitext (Class: WikiTextDataset) with specific config: {}\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:12,005 - INFO - Processing split 'train' for wikitext (Info: {'hf_split_name': 'train', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:12,005 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'train' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:22,841 - INFO - Raw base split 'validation' loaded/verified in 4.37s. Base size: 3760 examples.\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:22,841 - INFO - No percentage slice requested or applied for 'validation'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:22,841 - INFO - Raw data ready for wikitext split 'validation'. Size: 3760\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:22,841 - INFO - Processing split 'test' for wikitext (Info: {'hf_split_name': 'test', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:22,842 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'test' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m ************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m None\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:26,748 - INFO - Raw base split 'test' loaded/verified in 3.91s. Base size: 4358 examples.\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:26,748 - INFO - No percentage slice requested or applied for 'test'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:26,748 - INFO - Raw data ready for wikitext split 'test'. Size: 4358\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:26,748 - INFO - --- Finished prepare_data ---\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:19,253 - INFO - Raw base split 'train' loaded/verified in 7.25s. Base size: 36718 examples.\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:19,253 - INFO - No percentage slice requested or applied for 'train'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:19,253 - INFO - Raw data ready for wikitext split 'train'. Size: 36718\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:26,748 - INFO - Target tokenized path: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243218, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:26,748 - INFO - Tokenized data already exists at /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full. Skipping tokenization.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:19,253 - INFO - Processing split 'validation' for wikitext (Info: {'hf_split_name': 'validation', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:19,254 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'validation' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,570 - INFO - --- Setting up data for stage: fit (runs on all ranks) ---\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,570 - INFO - Setting up dataset: wikitext (tokenizer: gpt2). Expecting splits based on: {'train': {'hf_split_name': 'train', 'percentage': None}, 'validation': {'hf_split_name': 'validation', 'percentage': None}, 'test': {'hf_split_name': 'test', 'percentage': None}}\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,570 - INFO - Attempting to load 'train' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,570 - INFO - Loading packed dataset for split 'train' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,575 - INFO - Packed dataset loaded from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full with columns ['input_ids', 'labels', 'attention_mask']\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,575 - INFO - Successfully loaded 'train' split for wikitext.\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,575 - INFO - Attempting to load 'validation' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,575 - INFO - Loading packed dataset for split 'validation' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,579 - INFO - Packed dataset loaded from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full with columns ['input_ids', 'labels', 'attention_mask']\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,579 - INFO - Successfully loaded 'validation' split for wikitext.\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,580 - INFO - Setup complete for stage 'fit'. Combined datasets:\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,580 - INFO -   Train sources: 1, Total examples: 4723\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,580 - INFO -   Val sources: 1, Total examples: 488\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,580 - INFO -   Test sources: 0, Total examples: 0\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,582 - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,582 - INFO - You have specified an optimizer and/or scheduler within the DeepSpeed config. It is recommended to define it in `LightningModule.configure_optimizers`.\n",
      "\u001b[36m(RayTrainWorker pid=243215, ip=10.141.1.44)\u001b[0m Using /archive/SSD/home/abeatini/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:23,313 - INFO - Raw base split 'validation' loaded/verified in 4.06s. Base size: 3760 examples.\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:23,314 - INFO - No percentage slice requested or applied for 'validation'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:23,314 - INFO - Raw data ready for wikitext split 'validation'. Size: 3760\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:23,314 - INFO - Processing split 'test' for wikitext (Info: {'hf_split_name': 'test', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:23,314 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'test' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m Creating extension directory /archive/SSD/home/abeatini/.cache/torch_extensions/py310_cu121/fused_adam...\n",
      "\u001b[36m(RayTrainWorker pid=4130537)\u001b[0m Detected CUDA files, patching ldflags\n",
      "\u001b[36m(RayTrainWorker pid=4130537)\u001b[0m Emitting ninja build file /archive/SSD/home/abeatini/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...\n",
      "\u001b[36m(RayTrainWorker pid=4130537)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "\u001b[36m(RayTrainWorker pid=4130537)\u001b[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "\u001b[36m(RayTrainWorker pid=4130537)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(RayTrainWorker pid=4130537)\u001b[0m Building extension module fused_adam...\n",
      "\u001b[36m(RayTrainWorker pid=4130537)\u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4130537)\u001b[0m [1/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/deepspeed/ops/csrc/adam -isystem /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/torch/include -isystem /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/torch/include/TH -isystem /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/torch/include/THC -isystem /cm/shared/apps/cuda12.1/toolkit/12.1.1/include -isystem /cm/shared/apps/cuda12.1/toolkit/12.1.1 -isystem /davinci-1/home/abeatini/.conda/envs/shallow/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DBF16_AVAILABLE -c /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o \n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m ************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m None\n",
      "\u001b[36m(RayTrainWorker pid=4130537)\u001b[0m [2/3] /cm/shared/apps/cuda12.1/toolkit/12.1.1/bin/nvcc --generate-dependencies-with-compile --dependency-output multi_tensor_adam.cuda.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/deepspeed/ops/csrc/adam -isystem /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/torch/include -isystem /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/torch/include/TH -isystem /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/torch/include/THC -isystem /cm/shared/apps/cuda12.1/toolkit/12.1.1/include -isystem /cm/shared/apps/cuda12.1/toolkit/12.1.1 -isystem /davinci-1/home/abeatini/.conda/envs/shallow/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_80,code=compute_80 -DBF16_AVAILABLE -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -std=c++17 -c /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o \n",
      "\u001b[36m(RayTrainWorker pid=243215, ip=10.141.1.44)\u001b[0m Time to load fused_adam op: 34.132373094558716 seconds\n",
      "\u001b[36m(RayTrainWorker pid=4130537)\u001b[0m [3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/cm/shared/apps/cuda12.1/toolkit/12.1.1/lib64 -lcudart -o fused_adam.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4130537)\u001b[0m Loading extension module fused_adam...\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,473 - INFO - Raw base split 'test' loaded/verified in 4.16s. Base size: 4358 examples.\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,473 - INFO - No percentage slice requested or applied for 'test'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,473 - INFO - Raw data ready for wikitext split 'test'. Size: 4358\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,473 - INFO - --- Finished prepare_data ---\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,473 - INFO - Target tokenized path: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:55:27,473 - INFO - Tokenized data already exists at /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full. Skipping tokenization.\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,569 - INFO - --- Setting up data for stage: fit (runs on all ranks) ---\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,569 - INFO - Setting up dataset: wikitext (tokenizer: gpt2). Expecting splits based on: {'train': {'hf_split_name': 'train', 'percentage': None}, 'validation': {'hf_split_name': 'validation', 'percentage': None}, 'test': {'hf_split_name': 'test', 'percentage': None}}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,569 - INFO - Attempting to load 'train' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,569 - INFO - Loading packed dataset for split 'train' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,579 - INFO - Packed dataset loaded from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full with columns ['input_ids', 'labels', 'attention_mask']\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,576 - INFO - Successfully loaded 'train' split for wikitext.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,576 - INFO - Attempting to load 'validation' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,576 - INFO - Loading packed dataset for split 'validation' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,579 - INFO - Successfully loaded 'validation' split for wikitext.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,579 - INFO - Setup complete for stage 'fit'. Combined datasets:\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,579 - INFO -   Train sources: 1, Total examples: 4723\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,579 - INFO -   Val sources: 1, Total examples: 488\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,579 - INFO -   Test sources: 0, Total examples: 0\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=243216, ip=10.141.1.44)\u001b[0m 2025-06-26 18:55:27,581 - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4130536)\u001b[0m Using /archive/SSD/home/abeatini/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4130536)\u001b[0m Creating extension directory /archive/SSD/home/abeatini/.cache/torch_extensions/py310_cu121/fused_adam...\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m Parameter Offload: Total persistent parameters: 7985664 in 111 params\n",
      "\u001b[36m(RayTrainWorker pid=243215, ip=10.141.1.44)\u001b[0m [2025-06-26 18:56:05,071] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 2025-06-26 18:56:05,452 - INFO - \n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m   | Name  | Type            | Params | Params per Device | Mode\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m ---------------------------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 0 | model | GPT2LMHeadModel | 124 M  | 15.6 M            | eval\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m ---------------------------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 124 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 124 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 497.759   Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 0         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=4130538)\u001b[0m 164       Modules in eval mode\n",
      "\u001b[36m(RayTrainWorker pid=243215, ip=10.141.1.44)\u001b[0m 2025-06-26 18:56:05,475 - INFO - Creating train dataloader...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/296 [00:00<?, ?it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainTrainable pid=4150346)\u001b[0m 2025-06-26 19:00:37,374 - WARNING - Rewritten PROJECT_ROOT path to: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(TrainTrainable pid=4150346)\u001b[0m 2025-06-26 19:00:37,374 - INFO - Determined Project Root: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(TrainTrainable pid=4150346)\u001b[0m 2025-06-26 19:00:40,280 - INFO - PyTorch version 2.5.1+cu121 available.\n",
      "\u001b[36m(TrainTrainable pid=4150346)\u001b[0m 2025-06-26 19:00:40,580 - INFO - Registering dataset: wikitext\n",
      "\u001b[36m(TrainTrainable pid=4150346)\u001b[0m 2025-06-26 19:00:40,580 - INFO - Registering dataset: oscar\n",
      "\u001b[36m(TrainTrainable pid=4150346)\u001b[0m 2025-06-26 19:00:40,580 - INFO - Registering dataset: bookcorpus\n",
      "\u001b[36m(TrainTrainable pid=4150346)\u001b[0m 2025-06-26 19:00:40,580 - INFO - Registering dataset: openwebtext\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[36m(TorchTrainer pid=4150346)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=4150346)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4151002) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=4150346)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4151003) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=4150346)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4151006) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=4150346)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4151001) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=4150346)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=245174) world_rank=4, local_rank=0, node_rank=1\n",
      "\u001b[36m(TorchTrainer pid=4150346)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=245177) world_rank=5, local_rank=1, node_rank=1\n",
      "\u001b[36m(TorchTrainer pid=4150346)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=245176) world_rank=6, local_rank=2, node_rank=1\n",
      "\u001b[36m(TorchTrainer pid=4150346)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=245175) world_rank=7, local_rank=3, node_rank=1\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:49,378 - WARNING - Rewritten PROJECT_ROOT path to: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:49,378 - INFO - Determined Project Root: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:52,409 - INFO - PyTorch version 2.5.1+cu121 available.\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:52,716 - INFO - Registering dataset: wikitext\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:52,716 - INFO - Registering dataset: oscar\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:52,716 - INFO - Registering dataset: bookcorpus\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:52,716 - INFO - Registering dataset: openwebtext\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:53,393 - INFO - Relative cache_dir provided. Resolved to: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:53,395 - INFO - DataModule initialized.\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:53,395 - INFO -   Raw cache: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:53,395 - INFO -   Tokenized cache base for 'gpt2': /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:53,395 - WARNING - Tokenizer does not have a pad token. Setting pad_token = eos_token.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m [2025-06-26 19:00:54,041] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:00:49,474 - WARNING - Rewritten PROJECT_ROOT path to: /davinci-1/home/abeatini/pycharmProjects/shallowMind\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:00:49,474 - INFO - Determined Project Root: /davinci-1/home/abeatini/pycharmProjects/shallowMind\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/ray/train/lightning/_lightning_utils.py:262: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m `get_trial_name` is deprecated because the concept of a `Trial` will soon be removed in Ray Train.Ray Train will no longer assume that it's running within a Ray Tune `Trial` in the future. See this issue for more context and migration options: https://github.com/ray-project/ray/issues/49454. Disable these warnings by setting the environment variable: RAY_TRAIN_ENABLE_V2_MIGRATION_WARNINGS=0\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:55,806 - INFO - initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:00:57,379 - INFO - You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:00:52,611 - INFO - PyTorch version 2.5.1+cu121 available.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:00:57,402 - INFO - GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:00:57,402 - INFO - TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:00:57,402 - INFO - HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:00:57,405 - INFO - You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:59,308 - INFO - --- Starting prepare_data (runs only on rank 0) ---\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:59,308 - INFO - Using Raw cache directory: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:59,308 - INFO - Using Tokenized cache directory (for gpt2): /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:59,308 - INFO - Preparing dataset: wikitext (Class: WikiTextDataset) with specific config: {}\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:59,309 - INFO - Processing split 'train' for wikitext (Info: {'hf_split_name': 'train', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:59,309 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'train' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:00:52,935 - INFO - Registering dataset: wikitext\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:00:52,935 - INFO - Registering dataset: oscar\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:00:52,935 - INFO - Registering dataset: bookcorpus\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:00:52,935 - INFO - Registering dataset: openwebtext\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=245175, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:54,695 - INFO - Relative cache_dir provided. Resolved to: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=245175, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:54,696 - INFO - DataModule initialized.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=245175, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:54,696 - INFO -   Raw cache: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=245175, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:54,696 - INFO -   Tokenized cache base for 'gpt2': /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=245175, ip=10.141.1.44)\u001b[0m 2025-06-26 19:00:54,696 - WARNING - Tokenizer does not have a pad token. Setting pad_token = eos_token.\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m ************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m None\n",
      "\u001b[36m(RayTrainWorker pid=4151003)\u001b[0m [2025-06-26 19:00:55,108] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:05,660 - INFO - Raw base split 'train' loaded/verified in 6.35s. Base size: 36718 examples.\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:05,660 - INFO - No percentage slice requested or applied for 'train'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:05,660 - INFO - Raw data ready for wikitext split 'train'. Size: 36718\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:05,660 - INFO - Target tokenized path: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:05,660 - INFO - Tokenized data already exists at /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full. Skipping tokenization.\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:05,660 - INFO - Processing split 'validation' for wikitext (Info: {'hf_split_name': 'validation', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:05,660 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'validation' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4151003)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/ray/train/lightning/_lightning_utils.py:262: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151003)\u001b[0m `get_trial_name` is deprecated because the concept of a `Trial` will soon be removed in Ray Train.Ray Train will no longer assume that it's running within a Ray Tune `Trial` in the future. See this issue for more context and migration options: https://github.com/ray-project/ray/issues/49454. Disable these warnings by setting the environment variable: RAY_TRAIN_ENABLE_V2_MIGRATION_WARNINGS=0\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:00:57,404 - INFO - initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/8\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:00:59,302 - INFO - --- Starting prepare_data (runs only on rank 0) ---\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:00:59,303 - INFO - Using Raw cache directory: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:00:59,303 - INFO - Using Tokenized cache directory (for gpt2): /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:00:59,303 - INFO - Preparing dataset: wikitext (Class: WikiTextDataset) with specific config: {}\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:00:59,303 - INFO - Processing split 'train' for wikitext (Info: {'hf_split_name': 'train', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:00:59,303 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'train' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:09,307 - INFO - Raw base split 'validation' loaded/verified in 3.63s. Base size: 3760 examples.\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:09,308 - INFO - No percentage slice requested or applied for 'validation'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:09,308 - INFO - Raw data ready for wikitext split 'validation'. Size: 3760\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:09,308 - INFO - Processing split 'test' for wikitext (Info: {'hf_split_name': 'test', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:09,308 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'test' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m ************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m None\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:12,979 - INFO - Raw base split 'test' loaded/verified in 3.67s. Base size: 4358 examples.\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:12,979 - INFO - No percentage slice requested or applied for 'test'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:12,979 - INFO - Raw data ready for wikitext split 'test'. Size: 4358\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:12,979 - INFO - --- Finished prepare_data ---\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:05,676 - INFO - Raw base split 'train' loaded/verified in 6.37s. Base size: 36718 examples.\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:05,677 - INFO - No percentage slice requested or applied for 'train'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:05,677 - INFO - Raw data ready for wikitext split 'train'. Size: 36718\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:12,979 - INFO - Target tokenized path: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:12,979 - INFO - Tokenized data already exists at /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full. Skipping tokenization.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:05,677 - INFO - Processing split 'validation' for wikitext (Info: {'hf_split_name': 'validation', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:05,677 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'validation' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,588 - INFO - --- Setting up data for stage: fit (runs on all ranks) ---\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,588 - INFO - Setting up dataset: wikitext (tokenizer: gpt2). Expecting splits based on: {'train': {'hf_split_name': 'train', 'percentage': None}, 'validation': {'hf_split_name': 'validation', 'percentage': None}, 'test': {'hf_split_name': 'test', 'percentage': None}}\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,589 - INFO - Attempting to load 'train' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,589 - INFO - Loading packed dataset for split 'train' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,595 - INFO - Packed dataset loaded from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full with columns ['input_ids', 'labels', 'attention_mask']\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,595 - INFO - Successfully loaded 'train' split for wikitext.\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,595 - INFO - Attempting to load 'validation' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,595 - INFO - Loading packed dataset for split 'validation' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,598 - INFO - Packed dataset loaded from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full with columns ['input_ids', 'labels', 'attention_mask']\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,598 - INFO - Successfully loaded 'validation' split for wikitext.\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,598 - INFO - Setup complete for stage 'fit'. Combined datasets:\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,598 - INFO -   Train sources: 1, Total examples: 4723\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,599 - INFO -   Val sources: 1, Total examples: 488\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,599 - INFO -   Test sources: 0, Total examples: 0\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,602 - INFO - LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:13,602 - INFO - You have specified an optimizer and/or scheduler within the DeepSpeed config. It is recommended to define it in `LightningModule.configure_optimizers`.\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m Using /archive/SSD/home/abeatini/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m Detected CUDA files, patching ldflags\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m Emitting ninja build file /archive/SSD/home/abeatini/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m Building extension module fused_adam...\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:09,397 - INFO - Raw base split 'validation' loaded/verified in 3.74s. Base size: 3760 examples.\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:09,398 - INFO - No percentage slice requested or applied for 'validation'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:09,398 - INFO - Raw data ready for wikitext split 'validation'. Size: 3760\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:09,398 - INFO - Processing split 'test' for wikitext (Info: {'hf_split_name': 'test', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:09,398 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'test' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4151003)\u001b[0m Time to load fused_adam op: 1.612870693206787 seconds\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4151003)\u001b[0m Loading extension module fused_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m Parameter Offload: Total persistent parameters: 7985664 in 111 params\n",
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m [2025-06-26 19:01:19,401] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m ************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=245176, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:19,804 - INFO - Creating train dataloader...\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,490 - INFO - Raw base split 'test' loaded/verified in 4.09s. Base size: 4358 examples.\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,490 - INFO - No percentage slice requested or applied for 'test'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,490 - INFO - Raw data ready for wikitext split 'test'. Size: 4358\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,490 - INFO - --- Finished prepare_data ---\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,490 - INFO - Target tokenized path: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full\n",
      "\u001b[36m(RayTrainWorker pid=245174, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:13,490 - INFO - Tokenized data already exists at /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full. Skipping tokenization.\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,588 - INFO - --- Setting up data for stage: fit (runs on all ranks) ---\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,588 - INFO - Setting up dataset: wikitext (tokenizer: gpt2). Expecting splits based on: {'train': {'hf_split_name': 'train', 'percentage': None}, 'validation': {'hf_split_name': 'validation', 'percentage': None}, 'test': {'hf_split_name': 'test', 'percentage': None}}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,588 - INFO - Attempting to load 'train' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,589 - INFO - Loading packed dataset for split 'train' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,598 - INFO - Packed dataset loaded from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full with columns ['input_ids', 'labels', 'attention_mask']\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,595 - INFO - Successfully loaded 'train' split for wikitext.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,595 - INFO - Attempting to load 'validation' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,595 - INFO - Loading packed dataset for split 'validation' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,598 - INFO - Successfully loaded 'validation' split for wikitext.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,598 - INFO - Setup complete for stage 'fit'. Combined datasets:\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,598 - INFO -   Train sources: 1, Total examples: 4723\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,598 - INFO -   Val sources: 1, Total examples: 488\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,598 - INFO -   Test sources: 0, Total examples: 0\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151001)\u001b[0m 2025-06-26 19:01:13,602 - INFO - LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 2025-06-26 19:01:19,791 - INFO - \n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m   | Name  | Type            | Params | Params per Device | Mode\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m ---------------------------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 0 | model | GPT2LMHeadModel | 124 M  | 15.6 M            | eval\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m ---------------------------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 124 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 124 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 497.759   Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 0         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=4151002)\u001b[0m 164       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/296 [00:00<?, ?it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainTrainable pid=246717, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:37,465 - WARNING - Rewritten PROJECT_ROOT path to: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(TrainTrainable pid=246717, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:37,466 - INFO - Determined Project Root: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(TrainTrainable pid=246717, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:40,630 - INFO - PyTorch version 2.5.1+cu121 available.\n",
      "\u001b[36m(TrainTrainable pid=246717, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:40,934 - INFO - Registering dataset: wikitext\n",
      "\u001b[36m(TrainTrainable pid=246717, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:40,934 - INFO - Registering dataset: oscar\n",
      "\u001b[36m(TrainTrainable pid=246717, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:40,934 - INFO - Registering dataset: bookcorpus\n",
      "\u001b[36m(TrainTrainable pid=246717, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:40,934 - INFO - Registering dataset: openwebtext\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[36m(TorchTrainer pid=246717, ip=10.141.1.44)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=246717, ip=10.141.1.44)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=246798) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=246717, ip=10.141.1.44)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=246795) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=246717, ip=10.141.1.44)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=246797) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=246717, ip=10.141.1.44)\u001b[0m - (node_id=69c6e1206e43d88681cd8045e49f0a9d33ec8c3f67b086c503e5780a, ip=10.141.1.44, pid=246796) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=246717, ip=10.141.1.44)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4156086) world_rank=4, local_rank=0, node_rank=1\n",
      "\u001b[36m(TorchTrainer pid=246717, ip=10.141.1.44)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4156085) world_rank=5, local_rank=1, node_rank=1\n",
      "\u001b[36m(TorchTrainer pid=246717, ip=10.141.1.44)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4156091) world_rank=6, local_rank=2, node_rank=1\n",
      "\u001b[36m(TorchTrainer pid=246717, ip=10.141.1.44)\u001b[0m - (node_id=644bc7415f97efe4e878699a13e727896b92dad4c99d85ea2ad6ef4b, ip=10.141.1.24, pid=4156089) world_rank=7, local_rank=3, node_rank=1\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:49,932 - WARNING - Rewritten PROJECT_ROOT path to: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:49,932 - INFO - Determined Project Root: /davinci-1/home/abeatini/pycharmProjects/shallowMind\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:53,080 - INFO - PyTorch version 2.5.1+cu121 available.\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:53,403 - INFO - Registering dataset: wikitext\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:53,403 - INFO - Registering dataset: oscar\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:53,403 - INFO - Registering dataset: bookcorpus\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:53,403 - INFO - Registering dataset: openwebtext\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:01:53,915 - INFO - Relative cache_dir provided. Resolved to: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:01:53,917 - INFO - DataModule initialized.\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:01:53,917 - INFO -   Raw cache: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:01:53,917 - INFO -   Tokenized cache base for 'gpt2': /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:01:53,917 - WARNING - Tokenizer does not have a pad token. Setting pad_token = eos_token.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m [2025-06-26 19:01:54,368] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:01:49,930 - WARNING - Rewritten PROJECT_ROOT path to: /davinci-1/home/abeatini/pycharmProjects/shallowMind\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:01:49,931 - INFO - Determined Project Root: /davinci-1/home/abeatini/pycharmProjects/shallowMind\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/ray/train/lightning/_lightning_utils.py:262: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m `get_trial_name` is deprecated because the concept of a `Trial` will soon be removed in Ray Train.Ray Train will no longer assume that it's running within a Ray Tune `Trial` in the future. See this issue for more context and migration options: https://github.com/ray-project/ray/issues/49454. Disable these warnings by setting the environment variable: RAY_TRAIN_ENABLE_V2_MIGRATION_WARNINGS=0\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:01:56,346 - INFO - initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:57,374 - INFO - You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:57,396 - INFO - GPU available: True (cuda), used: True\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:57,396 - INFO - TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:57,396 - INFO - HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:57,399 - INFO - You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:58,914 - INFO - --- Starting prepare_data (runs only on rank 0) ---\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:58,914 - INFO - Using Raw cache directory: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:58,914 - INFO - Using Tokenized cache directory (for gpt2): /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:58,914 - INFO - Preparing dataset: wikitext (Class: WikiTextDataset) with specific config: {}\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:58,914 - INFO - Processing split 'train' for wikitext (Info: {'hf_split_name': 'train', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:58,914 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'train' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:01:53,118 - INFO - PyTorch version 2.5.1+cu121 available.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:01:53,442 - INFO - Registering dataset: wikitext\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:01:53,442 - INFO - Registering dataset: oscar\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:01:53,442 - INFO - Registering dataset: bookcorpus\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:01:53,442 - INFO - Registering dataset: openwebtext\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156089)\u001b[0m 2025-06-26 19:01:55,257 - INFO - Relative cache_dir provided. Resolved to: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156089)\u001b[0m 2025-06-26 19:01:55,257 - INFO - DataModule initialized.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156089)\u001b[0m 2025-06-26 19:01:55,257 - INFO -   Raw cache: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156089)\u001b[0m 2025-06-26 19:01:55,257 - INFO -   Tokenized cache base for 'gpt2': /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156089)\u001b[0m 2025-06-26 19:01:55,257 - WARNING - Tokenizer does not have a pad token. Setting pad_token = eos_token.\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m ************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m None\n",
      "\u001b[36m(RayTrainWorker pid=246796, ip=10.141.1.44)\u001b[0m [2025-06-26 19:01:55,748] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:05,164 - INFO - Raw base split 'train' loaded/verified in 6.24s. Base size: 36718 examples.\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:05,164 - INFO - No percentage slice requested or applied for 'train'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:05,164 - INFO - Raw data ready for wikitext split 'train'. Size: 36718\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:05,164 - INFO - Target tokenized path: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:05,164 - INFO - Tokenized data already exists at /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full. Skipping tokenization.\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:05,164 - INFO - Processing split 'validation' for wikitext (Info: {'hf_split_name': 'validation', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:05,164 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'validation' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=246797, ip=10.141.1.44)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/ray/train/lightning/_lightning_utils.py:262: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=246797, ip=10.141.1.44)\u001b[0m `get_trial_name` is deprecated because the concept of a `Trial` will soon be removed in Ray Train.Ray Train will no longer assume that it's running within a Ray Tune `Trial` in the future. See this issue for more context and migration options: https://github.com/ray-project/ray/issues/49454. Disable these warnings by setting the environment variable: RAY_TRAIN_ENABLE_V2_MIGRATION_WARNINGS=0\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=246797, ip=10.141.1.44)\u001b[0m 2025-06-26 19:01:57,402 - INFO - initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/8\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:01:58,925 - INFO - --- Starting prepare_data (runs only on rank 0) ---\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:01:58,925 - INFO - Using Raw cache directory: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:01:58,925 - INFO - Using Tokenized cache directory (for gpt2): /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:01:58,925 - INFO - Preparing dataset: wikitext (Class: WikiTextDataset) with specific config: {}\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:01:58,925 - INFO - Processing split 'train' for wikitext (Info: {'hf_split_name': 'train', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:01:58,925 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'train' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:09,060 - INFO - Raw base split 'validation' loaded/verified in 3.90s. Base size: 3760 examples.\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:09,061 - INFO - No percentage slice requested or applied for 'validation'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:09,061 - INFO - Raw data ready for wikitext split 'validation'. Size: 3760\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:09,061 - INFO - Processing split 'test' for wikitext (Info: {'hf_split_name': 'test', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:09,061 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'test' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m ************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m None\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:12,712 - INFO - Raw base split 'test' loaded/verified in 3.65s. Base size: 4358 examples.\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:12,713 - INFO - No percentage slice requested or applied for 'test'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:12,713 - INFO - Raw data ready for wikitext split 'test'. Size: 4358\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:12,713 - INFO - --- Finished prepare_data ---\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:05,239 - INFO - Raw base split 'train' loaded/verified in 6.32s. Base size: 36718 examples.\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:05,239 - INFO - No percentage slice requested or applied for 'train'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:05,239 - INFO - Raw data ready for wikitext split 'train'. Size: 36718\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:12,713 - INFO - Target tokenized path: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156086)\u001b[0m 2025-06-26 19:02:12,713 - INFO - Tokenized data already exists at /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full. Skipping tokenization.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:05,240 - INFO - Processing split 'validation' for wikitext (Info: {'hf_split_name': 'validation', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:05,240 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'validation' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,174 - INFO - --- Setting up data for stage: fit (runs on all ranks) ---\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,174 - INFO - Setting up dataset: wikitext (tokenizer: gpt2). Expecting splits based on: {'train': {'hf_split_name': 'train', 'percentage': None}, 'validation': {'hf_split_name': 'validation', 'percentage': None}, 'test': {'hf_split_name': 'test', 'percentage': None}}\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,174 - INFO - Attempting to load 'train' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,175 - INFO - Loading packed dataset for split 'train' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,180 - INFO - Packed dataset loaded from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full with columns ['input_ids', 'labels', 'attention_mask']\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,180 - INFO - Successfully loaded 'train' split for wikitext.\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,180 - INFO - Attempting to load 'validation' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,180 - INFO - Loading packed dataset for split 'validation' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,184 - INFO - Packed dataset loaded from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full with columns ['input_ids', 'labels', 'attention_mask']\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,184 - INFO - Successfully loaded 'validation' split for wikitext.\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,184 - INFO - Setup complete for stage 'fit'. Combined datasets:\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,184 - INFO -   Train sources: 1, Total examples: 4723\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,184 - INFO -   Val sources: 1, Total examples: 488\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,184 - INFO -   Test sources: 0, Total examples: 0\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,189 - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,189 - INFO - You have specified an optimizer and/or scheduler within the DeepSpeed config. It is recommended to define it in `LightningModule.configure_optimizers`.\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m Using /archive/SSD/home/abeatini/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:09,076 - INFO - Raw base split 'validation' loaded/verified in 3.84s. Base size: 3760 examples.\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:09,076 - INFO - No percentage slice requested or applied for 'validation'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:09,076 - INFO - Raw data ready for wikitext split 'validation'. Size: 3760\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:09,077 - INFO - Processing split 'test' for wikitext (Info: {'hf_split_name': 'test', 'percentage': None})\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:09,077 - INFO - Attempting load/download for wikitext (config: wikitext-2-raw-v1) BASE split 'test' (trust_remote_code=False) using cache /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/raw\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,076 - INFO - Raw base split 'test' loaded/verified in 4.00s. Base size: 4358 examples.\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,076 - INFO - No percentage slice requested or applied for 'test'. Using full base split.\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,076 - INFO - Raw data ready for wikitext split 'test'. Size: 4358\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,077 - INFO - --- Finished prepare_data ---\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,076 - INFO - Target tokenized path: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:13,077 - INFO - Tokenized data already exists at /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_test_full. Skipping tokenization.\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,174 - INFO - --- Setting up data for stage: fit (runs on all ranks) ---\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,174 - INFO - Setting up dataset: wikitext (tokenizer: gpt2). Expecting splits based on: {'train': {'hf_split_name': 'train', 'percentage': None}, 'validation': {'hf_split_name': 'validation', 'percentage': None}, 'test': {'hf_split_name': 'test', 'percentage': None}}\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,174 - INFO - Attempting to load 'train' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,174 - INFO - Loading packed dataset for split 'train' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_train_full\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,185 - INFO - Packed dataset loaded from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full with columns ['input_ids', 'labels', 'attention_mask']\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,181 - INFO - Successfully loaded 'train' split for wikitext.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,181 - INFO - Attempting to load 'validation' split for wikitext from: /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,181 - INFO - Loading packed dataset for split 'validation' from /davinci-1/home/abeatini/pycharmProjects/shallowMind/cached_data/tokenized/gpt2/wikitext_wikitext-2-raw-v1_validation_full\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,185 - INFO - Successfully loaded 'validation' split for wikitext.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,185 - INFO - Setup complete for stage 'fit'. Combined datasets:\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,185 - INFO -   Train sources: 1, Total examples: 4723\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,185 - INFO -   Val sources: 1, Total examples: 488\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,185 - INFO -   Test sources: 0, Total examples: 0\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m 2025-06-26 19:02:13,189 - INFO - LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=246795, ip=10.141.1.44)\u001b[0m Detected CUDA files, patching ldflags\n",
      "\u001b[36m(RayTrainWorker pid=246795, ip=10.141.1.44)\u001b[0m Emitting ninja build file /archive/SSD/home/abeatini/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...\n",
      "\u001b[36m(RayTrainWorker pid=246795, ip=10.141.1.44)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "\u001b[36m(RayTrainWorker pid=246795, ip=10.141.1.44)\u001b[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "\u001b[36m(RayTrainWorker pid=246795, ip=10.141.1.44)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(RayTrainWorker pid=246795, ip=10.141.1.44)\u001b[0m Building extension module fused_adam...\n",
      "\u001b[36m(RayTrainWorker pid=246795, ip=10.141.1.44)\u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m Time to load fused_adam op: 0.7089684009552002 seconds\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m ************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m None\n",
      "\u001b[36m(RayTrainWorker pid=246795, ip=10.141.1.44)\u001b[0m ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m Loading extension module fused_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m Parameter Offload: Total persistent parameters: 7985664 in 111 params\n",
      "\u001b[36m(RayTrainWorker pid=4156085)\u001b[0m [2025-06-26 19:02:24,550] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4156085)\u001b[0m 2025-06-26 19:02:25,109 - INFO - Creating train dataloader...\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:25,060 - INFO - \n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m   | Name  | Type            | Params | Params per Device | Mode\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m ---------------------------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 0 | model | GPT2LMHeadModel | 124 M  | 15.6 M            | eval\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m ---------------------------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 124 M     Trainable params\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 124 M     Total params\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 497.759   Total estimated model params size (MB)\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 0         Modules in train mode\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 164       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/296 [00:00<?, ?it/s] [0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m `loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m Using /archive/SSD/home/abeatini/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m Loading extension module fused_adam...\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/296 [00:02<13:02,  0.38it/s, v_num=0, train_loss=3.540]\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m Time to load fused_adam op: 0.7085003852844238 seconds\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "Epoch 0:   1%|          | 2/296 [00:02<07:07,  0.69it/s, v_num=0, train_loss=3.960]\n",
      "Epoch 0:   1%|          | 3/296 [00:03<05:09,  0.95it/s, v_num=0, train_loss=4.520]\n",
      "Epoch 0:   1%|▏         | 4/296 [00:03<04:10,  1.16it/s, v_num=0, train_loss=4.340]\n",
      "Epoch 0:   2%|▏         | 5/296 [00:03<03:34,  1.35it/s, v_num=0, train_loss=4.020]\n",
      "Epoch 0:   2%|▏         | 6/296 [00:03<03:10,  1.52it/s, v_num=0, train_loss=3.730]\n",
      "Epoch 0:   2%|▏         | 7/296 [00:04<02:55,  1.65it/s, v_num=0, train_loss=4.030]\n",
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m [2025-06-26 19:02:24,852] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "Epoch 0:   3%|▎         | 8/296 [00:04<02:42,  1.77it/s, v_num=0, train_loss=4.250]\n",
      "Epoch 0:   3%|▎         | 9/296 [00:04<02:31,  1.89it/s, v_num=0, train_loss=3.810]\n",
      "Epoch 0:   3%|▎         | 10/296 [00:05<02:23,  1.99it/s, v_num=0, train_loss=3.970]\n",
      "Epoch 0:   4%|▎         | 11/296 [00:05<02:16,  2.09it/s, v_num=0, train_loss=3.710]\n",
      "Epoch 0:   4%|▍         | 12/296 [00:05<02:10,  2.17it/s, v_num=0, train_loss=4.090]\n",
      "Epoch 0:   4%|▍         | 13/296 [00:05<02:05,  2.25it/s, v_num=0, train_loss=4.000]\n",
      "Epoch 0:   5%|▍         | 14/296 [00:06<02:01,  2.32it/s, v_num=0, train_loss=4.130]\n",
      "Epoch 0:   5%|▌         | 15/296 [00:06<01:57,  2.39it/s, v_num=0, train_loss=4.070]\n",
      "Epoch 0:   5%|▌         | 16/296 [00:06<01:54,  2.45it/s, v_num=0, train_loss=4.360]\n",
      "Epoch 0:   6%|▌         | 17/296 [00:06<01:51,  2.51it/s, v_num=0, train_loss=4.260]\n",
      "Epoch 0:   6%|▌         | 18/296 [00:07<01:48,  2.56it/s, v_num=0, train_loss=3.960]\n",
      "Epoch 0:   6%|▋         | 19/296 [00:07<01:46,  2.61it/s, v_num=0, train_loss=4.180]\n",
      "Epoch 0:   7%|▋         | 20/296 [00:07<01:44,  2.64it/s, v_num=0, train_loss=3.530]\n",
      "Epoch 0:   7%|▋         | 21/296 [00:07<01:42,  2.70it/s, v_num=0, train_loss=4.980]\n",
      "Epoch 0:   7%|▋         | 22/296 [00:08<01:40,  2.74it/s, v_num=0, train_loss=4.720]\n",
      "Epoch 0:   8%|▊         | 23/296 [00:08<01:38,  2.77it/s, v_num=0, train_loss=4.850]\n",
      "Epoch 0:   8%|▊         | 24/296 [00:08<01:36,  2.81it/s, v_num=0, train_loss=4.990]\n",
      "Epoch 0:   8%|▊         | 25/296 [00:08<01:35,  2.85it/s, v_num=0, train_loss=4.450]\n",
      "Epoch 0:   9%|▉         | 26/296 [00:09<01:33,  2.88it/s, v_num=0, train_loss=4.230]\n",
      "Epoch 0:   9%|▉         | 27/296 [00:09<01:32,  2.92it/s, v_num=0, train_loss=3.560]\n",
      "Epoch 0:   9%|▉         | 28/296 [00:09<01:30,  2.95it/s, v_num=0, train_loss=3.320]\n",
      "Epoch 0:  10%|▉         | 29/296 [00:09<01:29,  2.99it/s, v_num=0, train_loss=3.400]\n",
      "Epoch 0:  10%|█         | 30/296 [00:09<01:28,  3.01it/s, v_num=0, train_loss=3.830]\n",
      "Epoch 0:  10%|█         | 31/296 [00:10<01:27,  3.04it/s, v_num=0, train_loss=3.450]\n",
      "Epoch 0:  11%|█         | 32/296 [00:10<01:26,  3.07it/s, v_num=0, train_loss=3.370]\n",
      "Epoch 0:  11%|█         | 33/296 [00:10<01:25,  3.09it/s, v_num=0, train_loss=3.810]\n",
      "Epoch 0:  11%|█▏        | 34/296 [00:10<01:23,  3.12it/s, v_num=0, train_loss=2.900]\n",
      "Epoch 0:  12%|█▏        | 35/296 [00:11<01:22,  3.15it/s, v_num=0, train_loss=3.200]\n",
      "Epoch 0:  12%|█▏        | 36/296 [00:11<01:22,  3.17it/s, v_num=0, train_loss=3.190]\n",
      "Epoch 0:  12%|█▎        | 37/296 [00:11<01:21,  3.19it/s, v_num=0, train_loss=3.840]\n",
      "Epoch 0:  13%|█▎        | 38/296 [00:11<01:20,  3.22it/s, v_num=0, train_loss=3.380]\n",
      "Epoch 0:  13%|█▎        | 39/296 [00:12<01:19,  3.24it/s, v_num=0, train_loss=3.100]\n",
      "Epoch 0:  14%|█▎        | 40/296 [00:12<01:18,  3.26it/s, v_num=0, train_loss=3.060]\n",
      "Epoch 0:  14%|█▍        | 41/296 [00:12<01:17,  3.28it/s, v_num=0, train_loss=3.110]\n",
      "Epoch 0:  14%|█▍        | 42/296 [00:12<01:16,  3.30it/s, v_num=0, train_loss=3.050]\n",
      "Epoch 0:  15%|█▍        | 43/296 [00:13<01:16,  3.31it/s, v_num=0, train_loss=3.450]\n",
      "Epoch 0:  15%|█▍        | 44/296 [00:13<01:15,  3.33it/s, v_num=0, train_loss=3.580]\n",
      "Epoch 0:  15%|█▌        | 45/296 [00:13<01:15,  3.34it/s, v_num=0, train_loss=3.430]\n",
      "Epoch 0:  16%|█▌        | 46/296 [00:13<01:14,  3.36it/s, v_num=0, train_loss=3.150]\n",
      "Epoch 0:  16%|█▌        | 47/296 [00:13<01:13,  3.38it/s, v_num=0, train_loss=2.940]\n",
      "Epoch 0:  16%|█▌        | 48/296 [00:14<01:13,  3.39it/s, v_num=0, train_loss=3.310]\n",
      "Epoch 0:  17%|█▋        | 49/296 [00:14<01:12,  3.41it/s, v_num=0, train_loss=3.320]\n",
      "Epoch 0:  17%|█▋        | 50/296 [00:14<01:11,  3.43it/s, v_num=0, train_loss=3.110]\n",
      "Epoch 0:  17%|█▋        | 51/296 [00:14<01:11,  3.44it/s, v_num=0, train_loss=2.960]\n",
      "Epoch 0:  18%|█▊        | 52/296 [00:15<01:10,  3.45it/s, v_num=0, train_loss=3.010]\n",
      "Epoch 0:  18%|█▊        | 53/296 [00:15<01:10,  3.46it/s, v_num=0, train_loss=3.350]\n",
      "Epoch 0:  18%|█▊        | 54/296 [00:15<01:09,  3.47it/s, v_num=0, train_loss=3.310]\n",
      "Epoch 0:  19%|█▊        | 55/296 [00:15<01:09,  3.48it/s, v_num=0, train_loss=3.400]\n",
      "Epoch 0:  19%|█▉        | 56/296 [00:16<01:08,  3.49it/s, v_num=0, train_loss=3.090]\n",
      "Epoch 0:  19%|█▉        | 57/296 [00:16<01:08,  3.51it/s, v_num=0, train_loss=3.340]\n",
      "Epoch 0:  20%|█▉        | 58/296 [00:16<01:07,  3.52it/s, v_num=0, train_loss=2.960]\n",
      "Epoch 0:  20%|█▉        | 59/296 [00:16<01:07,  3.53it/s, v_num=0, train_loss=3.410]\n",
      "Epoch 0:  20%|██        | 60/296 [00:16<01:06,  3.54it/s, v_num=0, train_loss=3.280]\n",
      "Epoch 0:  21%|██        | 61/296 [00:17<01:06,  3.55it/s, v_num=0, train_loss=3.240]\n",
      "Epoch 0:  21%|██        | 62/296 [00:17<01:05,  3.56it/s, v_num=0, train_loss=3.790]\n",
      "Epoch 0:  21%|██▏       | 63/296 [00:17<01:05,  3.57it/s, v_num=0, train_loss=3.260]\n",
      "Epoch 0:  22%|██▏       | 64/296 [00:17<01:04,  3.58it/s, v_num=0, train_loss=3.630]\n",
      "Epoch 0:  22%|██▏       | 65/296 [00:18<01:04,  3.59it/s, v_num=0, train_loss=3.400]\n",
      "Epoch 0:  22%|██▏       | 66/296 [00:18<01:03,  3.60it/s, v_num=0, train_loss=3.200]\n",
      "Epoch 0:  23%|██▎       | 67/296 [00:18<01:03,  3.61it/s, v_num=0, train_loss=3.140]\n",
      "Epoch 0:  23%|██▎       | 68/296 [00:18<01:03,  3.62it/s, v_num=0, train_loss=3.250]\n",
      "Epoch 0:  23%|██▎       | 69/296 [00:19<01:02,  3.62it/s, v_num=0, train_loss=3.690]\n",
      "Epoch 0:  24%|██▎       | 70/296 [00:19<01:02,  3.63it/s, v_num=0, train_loss=3.180]\n",
      "Epoch 0:  24%|██▍       | 71/296 [00:19<01:01,  3.64it/s, v_num=0, train_loss=2.990]\n",
      "Epoch 0:  24%|██▍       | 72/296 [00:19<01:01,  3.65it/s, v_num=0, train_loss=2.980]\n",
      "Epoch 0:  25%|██▍       | 73/296 [00:19<01:00,  3.66it/s, v_num=0, train_loss=3.540]\n",
      "Epoch 0:  25%|██▌       | 74/296 [00:20<01:00,  3.67it/s, v_num=0, train_loss=3.450]\n",
      "Epoch 0:  25%|██▌       | 75/296 [00:20<01:00,  3.67it/s, v_num=0, train_loss=3.180]\n",
      "Epoch 0:  26%|██▌       | 76/296 [00:20<00:59,  3.68it/s, v_num=0, train_loss=3.340]\n",
      "Epoch 0:  26%|██▌       | 77/296 [00:20<00:59,  3.68it/s, v_num=0, train_loss=3.470]\n",
      "Epoch 0:  26%|██▋       | 78/296 [00:21<00:59,  3.69it/s, v_num=0, train_loss=2.870]\n",
      "Epoch 0:  27%|██▋       | 79/296 [00:21<00:58,  3.70it/s, v_num=0, train_loss=3.320]\n",
      "Epoch 0:  27%|██▋       | 80/296 [00:21<00:58,  3.71it/s, v_num=0, train_loss=3.230]\n",
      "Epoch 0:  27%|██▋       | 81/296 [00:21<00:57,  3.71it/s, v_num=0, train_loss=3.210]\n",
      "Epoch 0:  28%|██▊       | 82/296 [00:22<00:57,  3.72it/s, v_num=0, train_loss=3.320]\n",
      "Epoch 0:  28%|██▊       | 83/296 [00:22<00:57,  3.73it/s, v_num=0, train_loss=2.730]\n",
      "Epoch 0:  28%|██▊       | 84/296 [00:22<00:56,  3.73it/s, v_num=0, train_loss=3.790]\n",
      "Epoch 0:  29%|██▊       | 85/296 [00:22<00:56,  3.74it/s, v_num=0, train_loss=2.970]\n",
      "Epoch 0:  29%|██▉       | 86/296 [00:22<00:56,  3.75it/s, v_num=0, train_loss=3.260]\n",
      "Epoch 0:  29%|██▉       | 87/296 [00:23<00:55,  3.75it/s, v_num=0, train_loss=3.090]\n",
      "Epoch 0:  30%|██▉       | 88/296 [00:23<00:55,  3.76it/s, v_num=0, train_loss=3.290]\n",
      "Epoch 0:  30%|███       | 89/296 [00:23<00:55,  3.76it/s, v_num=0, train_loss=3.150]\n",
      "Epoch 0:  30%|███       | 90/296 [00:23<00:54,  3.77it/s, v_num=0, train_loss=2.920]\n",
      "Epoch 0:  31%|███       | 91/296 [00:24<00:54,  3.77it/s, v_num=0, train_loss=3.390]\n",
      "Epoch 0:  31%|███       | 92/296 [00:24<00:53,  3.78it/s, v_num=0, train_loss=3.220]\n",
      "Epoch 0:  31%|███▏      | 93/296 [00:24<00:53,  3.79it/s, v_num=0, train_loss=2.900]\n",
      "Epoch 0:  32%|███▏      | 94/296 [00:24<00:53,  3.79it/s, v_num=0, train_loss=2.890]\n",
      "Epoch 0:  32%|███▏      | 95/296 [00:25<00:52,  3.80it/s, v_num=0, train_loss=3.680]\n",
      "Epoch 0:  32%|███▏      | 96/296 [00:25<00:52,  3.80it/s, v_num=0, train_loss=2.960]\n",
      "Epoch 0:  33%|███▎      | 97/296 [00:25<00:52,  3.81it/s, v_num=0, train_loss=3.490]\n",
      "Epoch 0:  33%|███▎      | 98/296 [00:25<00:51,  3.81it/s, v_num=0, train_loss=3.240]\n",
      "Epoch 0:  33%|███▎      | 99/296 [00:25<00:51,  3.81it/s, v_num=0, train_loss=2.960]\n",
      "Epoch 0:  34%|███▍      | 100/296 [00:26<00:51,  3.81it/s, v_num=0, train_loss=3.220]\n",
      "Epoch 0:  34%|███▍      | 101/296 [00:26<00:51,  3.82it/s, v_num=0, train_loss=3.440]\n",
      "Epoch 0:  34%|███▍      | 102/296 [00:26<00:50,  3.82it/s, v_num=0, train_loss=3.710]\n",
      "Epoch 0:  35%|███▍      | 103/296 [00:26<00:50,  3.82it/s, v_num=0, train_loss=3.010]\n",
      "Epoch 0:  35%|███▌      | 104/296 [00:27<00:50,  3.83it/s, v_num=0, train_loss=3.280]\n",
      "Epoch 0:  35%|███▌      | 105/296 [00:27<00:49,  3.83it/s, v_num=0, train_loss=3.380]\n",
      "Epoch 0:  36%|███▌      | 106/296 [00:27<00:49,  3.84it/s, v_num=0, train_loss=3.220]\n",
      "Epoch 0:  36%|███▌      | 107/296 [00:27<00:49,  3.84it/s, v_num=0, train_loss=3.080]\n",
      "Epoch 0:  36%|███▋      | 108/296 [00:28<00:48,  3.85it/s, v_num=0, train_loss=3.690]\n",
      "Epoch 0:  37%|███▋      | 109/296 [00:28<00:48,  3.85it/s, v_num=0, train_loss=3.300]\n",
      "Epoch 0:  37%|███▋      | 110/296 [00:28<00:48,  3.85it/s, v_num=0, train_loss=3.250]\n",
      "Epoch 0:  38%|███▊      | 111/296 [00:28<00:47,  3.86it/s, v_num=0, train_loss=3.570]\n",
      "Epoch 0:  38%|███▊      | 112/296 [00:29<00:47,  3.86it/s, v_num=0, train_loss=3.020]\n",
      "Epoch 0:  38%|███▊      | 113/296 [00:29<00:47,  3.86it/s, v_num=0, train_loss=3.160]\n",
      "Epoch 0:  39%|███▊      | 114/296 [00:29<00:47,  3.87it/s, v_num=0, train_loss=2.970]\n",
      "Epoch 0:  39%|███▉      | 115/296 [00:29<00:46,  3.87it/s, v_num=0, train_loss=2.450]\n",
      "Epoch 0:  39%|███▉      | 116/296 [00:29<00:46,  3.88it/s, v_num=0, train_loss=3.270]\n",
      "Epoch 0:  40%|███▉      | 117/296 [00:30<00:46,  3.88it/s, v_num=0, train_loss=3.460]\n",
      "Epoch 0:  40%|███▉      | 118/296 [00:30<00:45,  3.88it/s, v_num=0, train_loss=3.030]\n",
      "Epoch 0:  40%|████      | 119/296 [00:30<00:45,  3.89it/s, v_num=0, train_loss=3.370]\n",
      "Epoch 0:  41%|████      | 120/296 [00:30<00:45,  3.89it/s, v_num=0, train_loss=3.820]\n",
      "Epoch 0:  41%|████      | 121/296 [00:31<00:44,  3.89it/s, v_num=0, train_loss=2.760]\n",
      "Epoch 0:  41%|████      | 122/296 [00:31<00:44,  3.90it/s, v_num=0, train_loss=2.850]\n",
      "Epoch 0:  42%|████▏     | 123/296 [00:31<00:44,  3.89it/s, v_num=0, train_loss=3.180]\n",
      "Epoch 0:  42%|████▏     | 124/296 [00:31<00:44,  3.90it/s, v_num=0, train_loss=2.950]\n",
      "Epoch 0:  42%|████▏     | 125/296 [00:32<00:43,  3.90it/s, v_num=0, train_loss=2.750]\n",
      "Epoch 0:  43%|████▎     | 126/296 [00:32<00:43,  3.90it/s, v_num=0, train_loss=2.990]\n",
      "Epoch 0:  43%|████▎     | 127/296 [00:32<00:43,  3.91it/s, v_num=0, train_loss=3.110]\n",
      "Epoch 0:  43%|████▎     | 128/296 [00:32<00:42,  3.91it/s, v_num=0, train_loss=3.120]\n",
      "Epoch 0:  44%|████▎     | 129/296 [00:32<00:42,  3.91it/s, v_num=0, train_loss=3.330]\n",
      "Epoch 0:  44%|████▍     | 130/296 [00:33<00:42,  3.92it/s, v_num=0, train_loss=2.960]\n",
      "Epoch 0:  44%|████▍     | 131/296 [00:33<00:42,  3.92it/s, v_num=0, train_loss=3.300]\n",
      "Epoch 0:  45%|████▍     | 132/296 [00:33<00:41,  3.92it/s, v_num=0, train_loss=3.420]\n",
      "Epoch 0:  45%|████▍     | 133/296 [00:33<00:41,  3.93it/s, v_num=0, train_loss=3.360]\n",
      "Epoch 0:  45%|████▌     | 134/296 [00:34<00:41,  3.92it/s, v_num=0, train_loss=3.290]\n",
      "Epoch 0:  46%|████▌     | 135/296 [00:34<00:40,  3.93it/s, v_num=0, train_loss=3.280]\n",
      "Epoch 0:  46%|████▌     | 136/296 [00:34<00:40,  3.93it/s, v_num=0, train_loss=3.130]\n",
      "Epoch 0:  46%|████▋     | 137/296 [00:34<00:40,  3.93it/s, v_num=0, train_loss=3.530]\n",
      "Epoch 0:  47%|████▋     | 138/296 [00:35<00:40,  3.93it/s, v_num=0, train_loss=3.040]\n",
      "Epoch 0:  47%|████▋     | 139/296 [00:35<00:39,  3.94it/s, v_num=0, train_loss=3.280]\n",
      "Epoch 0:  47%|████▋     | 140/296 [00:35<00:39,  3.94it/s, v_num=0, train_loss=3.020]\n",
      "Epoch 0:  48%|████▊     | 141/296 [00:35<00:39,  3.94it/s, v_num=0, train_loss=3.370]\n",
      "Epoch 0:  48%|████▊     | 142/296 [00:35<00:39,  3.95it/s, v_num=0, train_loss=2.810]\n",
      "Epoch 0:  48%|████▊     | 143/296 [00:36<00:38,  3.95it/s, v_num=0, train_loss=3.510]\n",
      "Epoch 0:  49%|████▊     | 144/296 [00:36<00:38,  3.95it/s, v_num=0, train_loss=3.310]\n",
      "Epoch 0:  49%|████▉     | 145/296 [00:36<00:38,  3.95it/s, v_num=0, train_loss=3.370]\n",
      "Epoch 0:  49%|████▉     | 146/296 [00:36<00:37,  3.95it/s, v_num=0, train_loss=2.860]\n",
      "Epoch 0:  50%|████▉     | 147/296 [00:37<00:37,  3.96it/s, v_num=0, train_loss=3.520]\n",
      "Epoch 0:  50%|█████     | 148/296 [00:37<00:37,  3.96it/s, v_num=0, train_loss=2.910]\n",
      "Epoch 0:  50%|█████     | 149/296 [00:37<00:37,  3.96it/s, v_num=0, train_loss=3.000]\n",
      "Epoch 0:  51%|█████     | 150/296 [00:37<00:36,  3.96it/s, v_num=0, train_loss=3.110]\n",
      "Epoch 0:  51%|█████     | 151/296 [00:38<00:36,  3.97it/s, v_num=0, train_loss=3.520]\n",
      "Epoch 0:  51%|█████▏    | 152/296 [00:38<00:36,  3.97it/s, v_num=0, train_loss=3.240]\n",
      "Epoch 0:  52%|█████▏    | 153/296 [00:38<00:36,  3.97it/s, v_num=0, train_loss=3.570]\n",
      "Epoch 0:  52%|█████▏    | 154/296 [00:38<00:35,  3.97it/s, v_num=0, train_loss=3.290]\n",
      "Epoch 0:  52%|█████▏    | 155/296 [00:38<00:35,  3.98it/s, v_num=0, train_loss=3.400]\n",
      "Epoch 0:  53%|█████▎    | 156/296 [00:39<00:35,  3.98it/s, v_num=0, train_loss=3.010]\n",
      "Epoch 0:  53%|█████▎    | 157/296 [00:39<00:34,  3.98it/s, v_num=0, train_loss=3.130]\n",
      "Epoch 0:  53%|█████▎    | 158/296 [00:39<00:34,  3.98it/s, v_num=0, train_loss=3.040]\n",
      "Epoch 0:  54%|█████▎    | 159/296 [00:39<00:34,  3.98it/s, v_num=0, train_loss=2.920]\n",
      "Epoch 0:  54%|█████▍    | 160/296 [00:40<00:34,  3.99it/s, v_num=0, train_loss=3.350]\n",
      "Epoch 0:  54%|█████▍    | 161/296 [00:40<00:33,  3.99it/s, v_num=0, train_loss=3.460]\n",
      "Epoch 0:  55%|█████▍    | 162/296 [00:40<00:33,  3.99it/s, v_num=0, train_loss=3.370]\n",
      "Epoch 0:  55%|█████▌    | 163/296 [00:40<00:33,  3.99it/s, v_num=0, train_loss=3.110]\n",
      "Epoch 0:  55%|█████▌    | 164/296 [00:41<00:33,  3.99it/s, v_num=0, train_loss=3.600]\n",
      "Epoch 0:  56%|█████▌    | 165/296 [00:41<00:32,  4.00it/s, v_num=0, train_loss=3.030]\n",
      "Epoch 0:  56%|█████▌    | 166/296 [00:41<00:32,  4.00it/s, v_num=0, train_loss=3.170]\n",
      "Epoch 0:  56%|█████▋    | 167/296 [00:41<00:32,  4.00it/s, v_num=0, train_loss=2.990]\n",
      "Epoch 0:  57%|█████▋    | 168/296 [00:41<00:31,  4.00it/s, v_num=0, train_loss=3.040]\n",
      "Epoch 0:  57%|█████▋    | 169/296 [00:42<00:31,  4.00it/s, v_num=0, train_loss=3.300]\n",
      "Epoch 0:  57%|█████▋    | 170/296 [00:42<00:31,  4.00it/s, v_num=0, train_loss=3.320]\n",
      "Epoch 0:  58%|█████▊    | 171/296 [00:42<00:31,  4.00it/s, v_num=0, train_loss=3.150]\n",
      "Epoch 0:  58%|█████▊    | 172/296 [00:43<00:31,  3.98it/s, v_num=0, train_loss=3.170]\n",
      "Epoch 0:  58%|█████▊    | 173/296 [00:43<00:30,  3.98it/s, v_num=0, train_loss=2.900]\n",
      "Epoch 0:  59%|█████▉    | 174/296 [00:43<00:30,  3.98it/s, v_num=0, train_loss=3.270]\n",
      "Epoch 0:  59%|█████▉    | 175/296 [00:43<00:30,  3.99it/s, v_num=0, train_loss=2.900]\n",
      "Epoch 0:  59%|█████▉    | 176/296 [00:44<00:30,  3.99it/s, v_num=0, train_loss=3.360]\n",
      "Epoch 0:  60%|█████▉    | 177/296 [00:44<00:29,  3.99it/s, v_num=0, train_loss=3.490]\n",
      "Epoch 0:  60%|██████    | 178/296 [00:44<00:29,  3.99it/s, v_num=0, train_loss=3.320]\n",
      "Epoch 0:  60%|██████    | 179/296 [00:44<00:29,  3.99it/s, v_num=0, train_loss=3.390]\n",
      "Epoch 0:  61%|██████    | 180/296 [00:45<00:29,  3.99it/s, v_num=0, train_loss=3.440]\n",
      "Epoch 0:  61%|██████    | 181/296 [00:45<00:28,  4.00it/s, v_num=0, train_loss=3.780]\n",
      "Epoch 0:  61%|██████▏   | 182/296 [00:45<00:28,  4.00it/s, v_num=0, train_loss=3.180]\n",
      "Epoch 0:  62%|██████▏   | 183/296 [00:45<00:28,  4.00it/s, v_num=0, train_loss=3.860]\n",
      "Epoch 0:  62%|██████▏   | 184/296 [00:45<00:27,  4.00it/s, v_num=0, train_loss=2.780]\n",
      "Epoch 0:  62%|██████▎   | 185/296 [00:46<00:27,  4.00it/s, v_num=0, train_loss=3.050]\n",
      "Epoch 0:  63%|██████▎   | 186/296 [00:46<00:27,  4.01it/s, v_num=0, train_loss=3.460]\n",
      "Epoch 0:  63%|██████▎   | 187/296 [00:46<00:27,  4.01it/s, v_num=0, train_loss=3.150]\n",
      "Epoch 0:  64%|██████▎   | 188/296 [00:46<00:26,  4.01it/s, v_num=0, train_loss=2.970]\n",
      "Epoch 0:  64%|██████▍   | 189/296 [00:47<00:26,  4.01it/s, v_num=0, train_loss=3.280]\n",
      "Epoch 0:  64%|██████▍   | 190/296 [00:47<00:26,  4.01it/s, v_num=0, train_loss=3.220]\n",
      "Epoch 0:  65%|██████▍   | 191/296 [00:47<00:26,  4.01it/s, v_num=0, train_loss=2.880]\n",
      "Epoch 0:  65%|██████▍   | 192/296 [00:47<00:25,  4.02it/s, v_num=0, train_loss=3.400]\n",
      "Epoch 0:  65%|██████▌   | 193/296 [00:48<00:25,  4.02it/s, v_num=0, train_loss=3.490]\n",
      "Epoch 0:  66%|██████▌   | 194/296 [00:48<00:25,  4.02it/s, v_num=0, train_loss=3.130]\n",
      "Epoch 0:  66%|██████▌   | 195/296 [00:48<00:25,  4.02it/s, v_num=0, train_loss=3.210]\n",
      "Epoch 0:  66%|██████▌   | 196/296 [00:48<00:24,  4.02it/s, v_num=0, train_loss=3.090]\n",
      "Epoch 0:  67%|██████▋   | 197/296 [00:48<00:24,  4.02it/s, v_num=0, train_loss=3.330]\n",
      "Epoch 0:  67%|██████▋   | 198/296 [00:49<00:24,  4.02it/s, v_num=0, train_loss=3.150]\n",
      "Epoch 0:  67%|██████▋   | 199/296 [00:49<00:24,  4.03it/s, v_num=0, train_loss=2.870]\n",
      "Epoch 0:  68%|██████▊   | 200/296 [00:49<00:23,  4.03it/s, v_num=0, train_loss=2.810]\n",
      "Epoch 0:  68%|██████▊   | 201/296 [00:49<00:23,  4.03it/s, v_num=0, train_loss=3.290]\n",
      "Epoch 0:  68%|██████▊   | 202/296 [00:50<00:23,  4.03it/s, v_num=0, train_loss=3.200]\n",
      "Epoch 0:  69%|██████▊   | 203/296 [00:50<00:23,  4.03it/s, v_num=0, train_loss=2.740]\n",
      "Epoch 0:  69%|██████▉   | 204/296 [00:50<00:22,  4.03it/s, v_num=0, train_loss=3.390]\n",
      "Epoch 0:  69%|██████▉   | 205/296 [00:50<00:22,  4.03it/s, v_num=0, train_loss=2.570]\n",
      "Epoch 0:  70%|██████▉   | 206/296 [00:51<00:22,  4.03it/s, v_num=0, train_loss=3.480]\n",
      "Epoch 0:  70%|██████▉   | 207/296 [00:51<00:22,  4.04it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 0:  70%|███████   | 208/296 [00:51<00:21,  4.04it/s, v_num=0, train_loss=2.800]\n",
      "Epoch 0:  71%|███████   | 209/296 [00:51<00:21,  4.04it/s, v_num=0, train_loss=3.210]\n",
      "Epoch 0:  71%|███████   | 210/296 [00:51<00:21,  4.04it/s, v_num=0, train_loss=2.980]\n",
      "Epoch 0:  71%|███████▏  | 211/296 [00:52<00:21,  4.04it/s, v_num=0, train_loss=3.170]\n",
      "Epoch 0:  72%|███████▏  | 212/296 [00:52<00:20,  4.04it/s, v_num=0, train_loss=3.530]\n",
      "Epoch 0:  72%|███████▏  | 213/296 [00:52<00:20,  4.04it/s, v_num=0, train_loss=3.230]\n",
      "Epoch 0:  72%|███████▏  | 214/296 [00:52<00:20,  4.05it/s, v_num=0, train_loss=3.450]\n",
      "Epoch 0:  73%|███████▎  | 215/296 [00:53<00:20,  4.05it/s, v_num=0, train_loss=3.430]\n",
      "Epoch 0:  73%|███████▎  | 216/296 [00:53<00:19,  4.05it/s, v_num=0, train_loss=3.200]\n",
      "Epoch 0:  73%|███████▎  | 217/296 [00:53<00:19,  4.05it/s, v_num=0, train_loss=3.080]\n",
      "Epoch 0:  74%|███████▎  | 218/296 [00:53<00:19,  4.05it/s, v_num=0, train_loss=3.130]\n",
      "Epoch 0:  74%|███████▍  | 219/296 [00:54<00:19,  4.05it/s, v_num=0, train_loss=3.670]\n",
      "Epoch 0:  74%|███████▍  | 220/296 [00:54<00:18,  4.05it/s, v_num=0, train_loss=3.470]\n",
      "Epoch 0:  75%|███████▍  | 221/296 [00:54<00:18,  4.05it/s, v_num=0, train_loss=3.060]\n",
      "Epoch 0:  75%|███████▌  | 222/296 [00:54<00:18,  4.05it/s, v_num=0, train_loss=3.210]\n",
      "Epoch 0:  75%|███████▌  | 223/296 [00:55<00:18,  4.05it/s, v_num=0, train_loss=3.370]\n",
      "Epoch 0:  76%|███████▌  | 224/296 [00:55<00:17,  4.06it/s, v_num=0, train_loss=2.750]\n",
      "Epoch 0:  76%|███████▌  | 225/296 [00:55<00:17,  4.06it/s, v_num=0, train_loss=3.130]\n",
      "Epoch 0:  76%|███████▋  | 226/296 [00:55<00:17,  4.06it/s, v_num=0, train_loss=3.310]\n",
      "Epoch 0:  77%|███████▋  | 227/296 [00:55<00:16,  4.06it/s, v_num=0, train_loss=3.270]\n",
      "Epoch 0:  77%|███████▋  | 228/296 [00:56<00:16,  4.06it/s, v_num=0, train_loss=3.130]\n",
      "Epoch 0:  77%|███████▋  | 229/296 [00:56<00:16,  4.06it/s, v_num=0, train_loss=3.010]\n",
      "Epoch 0:  78%|███████▊  | 230/296 [00:56<00:16,  4.06it/s, v_num=0, train_loss=3.430]\n",
      "Epoch 0:  78%|███████▊  | 231/296 [00:56<00:15,  4.06it/s, v_num=0, train_loss=3.280]\n",
      "Epoch 0:  78%|███████▊  | 232/296 [00:57<00:15,  4.07it/s, v_num=0, train_loss=3.490]\n",
      "Epoch 0:  79%|███████▊  | 233/296 [00:57<00:15,  4.07it/s, v_num=0, train_loss=3.240]\n",
      "Epoch 0:  79%|███████▉  | 234/296 [00:57<00:15,  4.07it/s, v_num=0, train_loss=3.000]\n",
      "Epoch 0:  79%|███████▉  | 235/296 [00:57<00:14,  4.07it/s, v_num=0, train_loss=3.720]\n",
      "Epoch 0:  80%|███████▉  | 236/296 [00:57<00:14,  4.07it/s, v_num=0, train_loss=3.330]\n",
      "Epoch 0:  80%|████████  | 237/296 [00:58<00:14,  4.07it/s, v_num=0, train_loss=3.250]\n",
      "Epoch 0:  80%|████████  | 238/296 [00:58<00:14,  4.07it/s, v_num=0, train_loss=2.970]\n",
      "Epoch 0:  81%|████████  | 239/296 [00:58<00:13,  4.07it/s, v_num=0, train_loss=3.080]\n",
      "Epoch 0:  81%|████████  | 240/296 [00:58<00:13,  4.07it/s, v_num=0, train_loss=3.480]\n",
      "Epoch 0:  81%|████████▏ | 241/296 [00:59<00:13,  4.07it/s, v_num=0, train_loss=3.370]\n",
      "Epoch 0:  82%|████████▏ | 242/296 [00:59<00:13,  4.07it/s, v_num=0, train_loss=3.090]\n",
      "Epoch 0:  82%|████████▏ | 243/296 [00:59<00:13,  4.07it/s, v_num=0, train_loss=2.830]\n",
      "Epoch 0:  82%|████████▏ | 244/296 [00:59<00:12,  4.07it/s, v_num=0, train_loss=2.810]\n",
      "Epoch 0:  83%|████████▎ | 245/296 [01:00<00:12,  4.08it/s, v_num=0, train_loss=3.040]\n",
      "Epoch 0:  83%|████████▎ | 246/296 [01:00<00:12,  4.08it/s, v_num=0, train_loss=2.630]\n",
      "Epoch 0:  83%|████████▎ | 247/296 [01:00<00:12,  4.08it/s, v_num=0, train_loss=3.320]\n",
      "Epoch 0:  84%|████████▍ | 248/296 [01:00<00:11,  4.08it/s, v_num=0, train_loss=3.510]\n",
      "Epoch 0:  84%|████████▍ | 249/296 [01:01<00:11,  4.08it/s, v_num=0, train_loss=3.340]\n",
      "Epoch 0:  84%|████████▍ | 250/296 [01:01<00:11,  4.08it/s, v_num=0, train_loss=3.380]\n",
      "Epoch 0:  85%|████████▍ | 251/296 [01:01<00:11,  4.08it/s, v_num=0, train_loss=3.240]\n",
      "Epoch 0:  85%|████████▌ | 252/296 [01:01<00:10,  4.08it/s, v_num=0, train_loss=3.530]\n",
      "Epoch 0:  85%|████████▌ | 253/296 [01:01<00:10,  4.08it/s, v_num=0, train_loss=3.220]\n",
      "Epoch 0:  86%|████████▌ | 254/296 [01:02<00:10,  4.08it/s, v_num=0, train_loss=2.940]\n",
      "Epoch 0:  86%|████████▌ | 255/296 [01:02<00:10,  4.08it/s, v_num=0, train_loss=3.180]\n",
      "Epoch 0:  86%|████████▋ | 256/296 [01:02<00:09,  4.09it/s, v_num=0, train_loss=3.050]\n",
      "Epoch 0:  87%|████████▋ | 257/296 [01:02<00:09,  4.09it/s, v_num=0, train_loss=3.060]\n",
      "Epoch 0:  87%|████████▋ | 258/296 [01:03<00:09,  4.09it/s, v_num=0, train_loss=3.240]\n",
      "Epoch 0:  88%|████████▊ | 259/296 [01:03<00:09,  4.09it/s, v_num=0, train_loss=3.500]\n",
      "Epoch 0:  88%|████████▊ | 260/296 [01:03<00:08,  4.09it/s, v_num=0, train_loss=2.950]\n",
      "Epoch 0:  88%|████████▊ | 261/296 [01:03<00:08,  4.09it/s, v_num=0, train_loss=2.950]\n",
      "Epoch 0:  89%|████████▊ | 262/296 [01:04<00:08,  4.09it/s, v_num=0, train_loss=2.990]\n",
      "Epoch 0:  89%|████████▉ | 263/296 [01:04<00:08,  4.09it/s, v_num=0, train_loss=3.090]\n",
      "Epoch 0:  89%|████████▉ | 264/296 [01:04<00:07,  4.09it/s, v_num=0, train_loss=3.370]\n",
      "Epoch 0:  90%|████████▉ | 265/296 [01:04<00:07,  4.10it/s, v_num=0, train_loss=3.110]\n",
      "Epoch 0:  90%|████████▉ | 266/296 [01:04<00:07,  4.10it/s, v_num=0, train_loss=3.140]\n",
      "Epoch 0:  90%|█████████ | 267/296 [01:05<00:07,  4.10it/s, v_num=0, train_loss=3.330]\n",
      "Epoch 0:  91%|█████████ | 268/296 [01:05<00:06,  4.10it/s, v_num=0, train_loss=3.070]\n",
      "Epoch 0:  91%|█████████ | 269/296 [01:05<00:06,  4.10it/s, v_num=0, train_loss=3.460]\n",
      "Epoch 0:  91%|█████████ | 270/296 [01:05<00:06,  4.10it/s, v_num=0, train_loss=3.050]\n",
      "Epoch 0:  92%|█████████▏| 271/296 [01:06<00:06,  4.10it/s, v_num=0, train_loss=3.220]\n",
      "Epoch 0:  92%|█████████▏| 272/296 [01:06<00:05,  4.10it/s, v_num=0, train_loss=3.380]\n",
      "Epoch 0:  92%|█████████▏| 273/296 [01:06<00:05,  4.10it/s, v_num=0, train_loss=2.730]\n",
      "Epoch 0:  93%|█████████▎| 274/296 [01:06<00:05,  4.10it/s, v_num=0, train_loss=3.390]\n",
      "Epoch 0:  93%|█████████▎| 275/296 [01:07<00:05,  4.10it/s, v_num=0, train_loss=3.120]\n",
      "Epoch 0:  93%|█████████▎| 276/296 [01:07<00:04,  4.10it/s, v_num=0, train_loss=3.230]\n",
      "Epoch 0:  94%|█████████▎| 277/296 [01:07<00:04,  4.10it/s, v_num=0, train_loss=3.170]\n",
      "Epoch 0:  94%|█████████▍| 278/296 [01:07<00:04,  4.10it/s, v_num=0, train_loss=3.380]\n",
      "Epoch 0:  94%|█████████▍| 279/296 [01:07<00:04,  4.11it/s, v_num=0, train_loss=3.320]\n",
      "Epoch 0:  95%|█████████▍| 280/296 [01:08<00:03,  4.11it/s, v_num=0, train_loss=3.130]\n",
      "Epoch 0:  95%|█████████▍| 281/296 [01:08<00:03,  4.11it/s, v_num=0, train_loss=2.870]\n",
      "Epoch 0:  95%|█████████▌| 282/296 [01:08<00:03,  4.11it/s, v_num=0, train_loss=3.550]\n",
      "Epoch 0:  96%|█████████▌| 283/296 [01:08<00:03,  4.11it/s, v_num=0, train_loss=3.250]\n",
      "Epoch 0:  96%|█████████▌| 284/296 [01:09<00:02,  4.11it/s, v_num=0, train_loss=3.310]\n",
      "Epoch 0:  96%|█████████▋| 285/296 [01:09<00:02,  4.11it/s, v_num=0, train_loss=3.060]\n",
      "Epoch 0:  97%|█████████▋| 286/296 [01:09<00:02,  4.11it/s, v_num=0, train_loss=3.300]\n",
      "Epoch 0:  97%|█████████▋| 287/296 [01:09<00:02,  4.11it/s, v_num=0, train_loss=2.970]\n",
      "Epoch 0:  97%|█████████▋| 288/296 [01:10<00:01,  4.11it/s, v_num=0, train_loss=3.030]\n",
      "Epoch 0:  98%|█████████▊| 289/296 [01:10<00:01,  4.11it/s, v_num=0, train_loss=3.450]\n",
      "Epoch 0:  98%|█████████▊| 290/296 [01:10<00:01,  4.11it/s, v_num=0, train_loss=3.100]\n",
      "Epoch 0:  98%|█████████▊| 291/296 [01:10<00:01,  4.11it/s, v_num=0, train_loss=3.140]\n",
      "Epoch 0:  99%|█████████▊| 292/296 [01:10<00:00,  4.12it/s, v_num=0, train_loss=3.210]\n",
      "Epoch 0:  99%|█████████▉| 293/296 [01:11<00:00,  4.12it/s, v_num=0, train_loss=3.100]\n",
      "Epoch 0:  99%|█████████▉| 294/296 [01:11<00:00,  4.12it/s, v_num=0, train_loss=3.350]\n",
      "Epoch 0: 100%|█████████▉| 295/296 [01:11<00:00,  4.12it/s, v_num=0, train_loss=3.360]\n",
      "Epoch 0: 100%|██████████| 296/296 [01:11<00:00,  4.12it/s, v_num=0, train_loss=2.720]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m /davinci-1/home/abeatini/.conda/envs/shallow/lib/python3.10/site-packages/pytorch_lightning/strategies/deepspeed.py:640: When saving the DeepSpeed Stage 3 checkpoint, each worker will save a shard of the checkpoint within a directory. If a single file is required after training, see https://lightning.ai/docs/pytorch/stable/advanced/model_parallel.html#deepspeed-zero-stage-3-single-file for instructions.\n",
      "\u001b[36m(RayTrainWorker pid=246796, ip=10.141.1.44)\u001b[0m 2025-06-26 19:02:25,108 - INFO - Creating train dataloader...\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156091)\u001b[0m `loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=4156085)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/davinci-1/home/abeatini/ray_results/TorchTrainer_2025-06-26_19-01-27/TorchTrainer_32cee_00000_0_2025-06-26_19-01-27/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 296/296 [01:12<00:00,  4.07it/s, v_num=0, train_loss=2.720]\n",
      "Epoch 1:   0%|          | 0/296 [00:00<?, ?it/s, v_num=0, train_loss=2.720]          \n",
      "Epoch 1:   0%|          | 1/296 [00:00<01:12,  4.07it/s, v_num=0, train_loss=2.340]\n",
      "Epoch 1:   1%|          | 2/296 [00:00<01:10,  4.19it/s, v_num=0, train_loss=2.780]\n",
      "Epoch 1:   1%|          | 3/296 [00:00<01:09,  4.23it/s, v_num=0, train_loss=2.270]\n",
      "Epoch 1:   1%|▏         | 4/296 [00:00<01:08,  4.25it/s, v_num=0, train_loss=2.440]\n",
      "Epoch 1:   2%|▏         | 5/296 [00:01<01:08,  4.26it/s, v_num=0, train_loss=3.240]\n",
      "Epoch 1:   2%|▏         | 6/296 [00:01<01:08,  4.26it/s, v_num=0, train_loss=2.450]\n",
      "Epoch 1:   2%|▏         | 7/296 [00:01<01:07,  4.27it/s, v_num=0, train_loss=2.890]\n",
      "Epoch 1:   3%|▎         | 8/296 [00:01<01:07,  4.27it/s, v_num=0, train_loss=2.360]\n",
      "Epoch 1:   3%|▎         | 9/296 [00:02<01:07,  4.27it/s, v_num=0, train_loss=2.910]\n",
      "Epoch 1:   3%|▎         | 10/296 [00:02<01:08,  4.19it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 1:   4%|▎         | 11/296 [00:02<01:07,  4.21it/s, v_num=0, train_loss=3.060]\n",
      "Epoch 1:   4%|▍         | 12/296 [00:02<01:07,  4.22it/s, v_num=0, train_loss=2.220]\n",
      "Epoch 1:   4%|▍         | 13/296 [00:03<01:06,  4.24it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 1:   5%|▍         | 14/296 [00:03<01:06,  4.24it/s, v_num=0, train_loss=2.470]\n",
      "Epoch 1:   5%|▌         | 15/296 [00:03<01:06,  4.25it/s, v_num=0, train_loss=3.030]\n",
      "Epoch 1:   5%|▌         | 16/296 [00:03<01:06,  4.22it/s, v_num=0, train_loss=2.680]\n",
      "Epoch 1:   6%|▌         | 17/296 [00:04<01:06,  4.22it/s, v_num=0, train_loss=2.380]\n",
      "Epoch 1:   6%|▌         | 18/296 [00:04<01:05,  4.23it/s, v_num=0, train_loss=2.510]\n",
      "Epoch 1:   6%|▋         | 19/296 [00:04<01:05,  4.24it/s, v_num=0, train_loss=2.410]\n",
      "Epoch 1:   7%|▋         | 20/296 [00:04<01:05,  4.24it/s, v_num=0, train_loss=3.040]\n",
      "Epoch 1:   7%|▋         | 21/296 [00:04<01:04,  4.25it/s, v_num=0, train_loss=2.860]\n",
      "Epoch 1:   7%|▋         | 22/296 [00:05<01:04,  4.25it/s, v_num=0, train_loss=3.020]\n",
      "Epoch 1:   8%|▊         | 23/296 [00:05<01:04,  4.26it/s, v_num=0, train_loss=2.640]\n",
      "Epoch 1:   8%|▊         | 24/296 [00:05<01:03,  4.27it/s, v_num=0, train_loss=2.820]\n",
      "Epoch 1:   8%|▊         | 25/296 [00:05<01:03,  4.27it/s, v_num=0, train_loss=2.520]\n",
      "Epoch 1:   9%|▉         | 26/296 [00:06<01:03,  4.27it/s, v_num=0, train_loss=2.530]\n",
      "Epoch 1:   9%|▉         | 27/296 [00:06<01:02,  4.27it/s, v_num=0, train_loss=2.880]\n",
      "Epoch 1:   9%|▉         | 28/296 [00:06<01:02,  4.28it/s, v_num=0, train_loss=2.490]\n",
      "Epoch 1:  10%|▉         | 29/296 [00:06<01:02,  4.28it/s, v_num=0, train_loss=2.420]\n",
      "Epoch 1:  10%|█         | 30/296 [00:07<01:02,  4.28it/s, v_num=0, train_loss=3.050]\n",
      "Epoch 1:  10%|█         | 31/296 [00:07<01:01,  4.28it/s, v_num=0, train_loss=2.870]\n",
      "Epoch 1:  11%|█         | 32/296 [00:07<01:01,  4.28it/s, v_num=0, train_loss=2.730]\n",
      "Epoch 1:  11%|█         | 33/296 [00:07<01:01,  4.29it/s, v_num=0, train_loss=2.730]\n",
      "Epoch 1:  11%|█▏        | 34/296 [00:07<01:01,  4.28it/s, v_num=0, train_loss=2.670]\n",
      "Epoch 1:  12%|█▏        | 35/296 [00:08<01:00,  4.28it/s, v_num=0, train_loss=2.680]\n",
      "Epoch 1:  12%|█▏        | 36/296 [00:08<01:00,  4.28it/s, v_num=0, train_loss=2.970]\n",
      "Epoch 1:  12%|█▎        | 37/296 [00:08<01:00,  4.29it/s, v_num=0, train_loss=2.380]\n",
      "Epoch 1:  13%|█▎        | 38/296 [00:08<01:00,  4.29it/s, v_num=0, train_loss=2.560]\n",
      "Epoch 1:  13%|█▎        | 39/296 [00:09<00:59,  4.28it/s, v_num=0, train_loss=3.090]\n",
      "Epoch 1:  14%|█▎        | 40/296 [00:09<00:59,  4.29it/s, v_num=0, train_loss=2.780]\n",
      "Epoch 1:  14%|█▍        | 41/296 [00:09<00:59,  4.29it/s, v_num=0, train_loss=2.610]\n",
      "Epoch 1:  14%|█▍        | 42/296 [00:09<00:59,  4.29it/s, v_num=0, train_loss=3.140]\n",
      "Epoch 1:  15%|█▍        | 43/296 [00:10<01:00,  4.19it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 1:  15%|█▍        | 44/296 [00:10<01:00,  4.19it/s, v_num=0, train_loss=3.030]\n",
      "Epoch 1:  15%|█▌        | 45/296 [00:10<00:59,  4.20it/s, v_num=0, train_loss=2.610]\n",
      "Epoch 1:  16%|█▌        | 46/296 [00:10<00:59,  4.20it/s, v_num=0, train_loss=2.530]\n",
      "Epoch 1:  16%|█▌        | 47/296 [00:11<00:59,  4.20it/s, v_num=0, train_loss=2.570]\n",
      "Epoch 1:  16%|█▌        | 48/296 [00:11<00:58,  4.21it/s, v_num=0, train_loss=2.570]\n",
      "Epoch 1:  17%|█▋        | 49/296 [00:11<00:58,  4.21it/s, v_num=0, train_loss=2.300]\n",
      "Epoch 1:  17%|█▋        | 50/296 [00:11<00:58,  4.22it/s, v_num=0, train_loss=2.890]\n",
      "Epoch 1:  17%|█▋        | 51/296 [00:12<00:58,  4.22it/s, v_num=0, train_loss=2.360]\n",
      "Epoch 1:  18%|█▊        | 52/296 [00:12<00:57,  4.22it/s, v_num=0, train_loss=2.530]\n",
      "Epoch 1:  18%|█▊        | 53/296 [00:12<00:57,  4.23it/s, v_num=0, train_loss=2.660]\n",
      "Epoch 1:  18%|█▊        | 54/296 [00:12<00:57,  4.23it/s, v_num=0, train_loss=2.810]\n",
      "Epoch 1:  19%|█▊        | 55/296 [00:13<00:56,  4.23it/s, v_num=0, train_loss=2.540]\n",
      "Epoch 1:  19%|█▉        | 56/296 [00:13<00:56,  4.21it/s, v_num=0, train_loss=2.450]\n",
      "Epoch 1:  19%|█▉        | 57/296 [00:13<00:56,  4.22it/s, v_num=0, train_loss=2.360]\n",
      "Epoch 1:  20%|█▉        | 58/296 [00:13<00:56,  4.22it/s, v_num=0, train_loss=2.860]\n",
      "Epoch 1:  20%|█▉        | 59/296 [00:13<00:56,  4.22it/s, v_num=0, train_loss=2.720]\n",
      "Epoch 1:  20%|██        | 60/296 [00:14<00:55,  4.22it/s, v_num=0, train_loss=2.720]\n",
      "Epoch 1:  20%|██        | 60/296 [00:14<00:55,  4.22it/s, v_num=0, train_loss=3.000]\n",
      "Epoch 1:  21%|██        | 61/296 [00:14<00:55,  4.22it/s, v_num=0, train_loss=3.330]\n",
      "Epoch 1:  21%|██        | 62/296 [00:14<00:55,  4.22it/s, v_num=0, train_loss=2.980]\n",
      "Epoch 1:  21%|██▏       | 63/296 [00:14<00:55,  4.22it/s, v_num=0, train_loss=2.970]\n",
      "Epoch 1:  22%|██▏       | 64/296 [00:15<00:54,  4.22it/s, v_num=0, train_loss=2.690]\n",
      "Epoch 1:  22%|██▏       | 65/296 [00:15<00:54,  4.23it/s, v_num=0, train_loss=2.710]\n",
      "Epoch 1:  22%|██▏       | 66/296 [00:15<00:54,  4.23it/s, v_num=0, train_loss=2.760]\n",
      "Epoch 1:  23%|██▎       | 67/296 [00:15<00:54,  4.23it/s, v_num=0, train_loss=2.900]\n",
      "Epoch 1:  23%|██▎       | 68/296 [00:16<00:53,  4.23it/s, v_num=0, train_loss=2.880]\n",
      "Epoch 1:  23%|██▎       | 69/296 [00:16<00:53,  4.23it/s, v_num=0, train_loss=3.290]\n",
      "Epoch 1:  24%|██▎       | 70/296 [00:16<00:53,  4.24it/s, v_num=0, train_loss=2.630]\n",
      "Epoch 1:  24%|██▍       | 71/296 [00:16<00:53,  4.24it/s, v_num=0, train_loss=2.940]\n",
      "Epoch 1:  24%|██▍       | 72/296 [00:16<00:52,  4.24it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 1:  25%|██▍       | 73/296 [00:17<00:52,  4.24it/s, v_num=0, train_loss=2.130]\n",
      "Epoch 1:  25%|██▌       | 74/296 [00:17<00:52,  4.24it/s, v_num=0, train_loss=2.370]\n",
      "Epoch 1:  25%|██▌       | 75/296 [00:17<00:52,  4.24it/s, v_num=0, train_loss=2.930]\n",
      "Epoch 1:  26%|██▌       | 76/296 [00:17<00:51,  4.24it/s, v_num=0, train_loss=3.060]\n",
      "Epoch 1:  26%|██▌       | 77/296 [00:18<00:51,  4.24it/s, v_num=0, train_loss=2.500]\n",
      "Epoch 1:  26%|██▋       | 78/296 [00:18<00:51,  4.24it/s, v_num=0, train_loss=3.000]\n",
      "Epoch 1:  27%|██▋       | 79/296 [00:18<00:51,  4.24it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 1:  27%|██▋       | 80/296 [00:18<00:50,  4.24it/s, v_num=0, train_loss=2.670]\n",
      "Epoch 1:  27%|██▋       | 81/296 [00:19<00:50,  4.24it/s, v_num=0, train_loss=2.740]\n",
      "Epoch 1:  28%|██▊       | 82/296 [00:19<00:50,  4.24it/s, v_num=0, train_loss=2.680]\n",
      "Epoch 1:  28%|██▊       | 83/296 [00:19<00:50,  4.23it/s, v_num=0, train_loss=3.000]\n",
      "Epoch 1:  28%|██▊       | 84/296 [00:19<00:50,  4.23it/s, v_num=0, train_loss=2.630]\n",
      "Epoch 1:  29%|██▊       | 85/296 [00:20<00:49,  4.24it/s, v_num=0, train_loss=3.050]\n",
      "Epoch 1:  29%|██▉       | 86/296 [00:20<00:49,  4.24it/s, v_num=0, train_loss=2.680]\n",
      "Epoch 1:  29%|██▉       | 87/296 [00:20<00:49,  4.24it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 1:  30%|██▉       | 88/296 [00:20<00:49,  4.24it/s, v_num=0, train_loss=2.710]\n",
      "Epoch 1:  30%|███       | 89/296 [00:20<00:48,  4.24it/s, v_num=0, train_loss=3.190]\n",
      "Epoch 1:  30%|███       | 90/296 [00:21<00:48,  4.24it/s, v_num=0, train_loss=2.950]\n",
      "Epoch 1:  31%|███       | 91/296 [00:21<00:48,  4.24it/s, v_num=0, train_loss=2.910]\n",
      "Epoch 1:  31%|███       | 92/296 [00:21<00:48,  4.25it/s, v_num=0, train_loss=2.840]\n",
      "Epoch 1:  31%|███▏      | 93/296 [00:21<00:47,  4.25it/s, v_num=0, train_loss=2.660]\n",
      "Epoch 1:  32%|███▏      | 94/296 [00:22<00:47,  4.25it/s, v_num=0, train_loss=2.340]\n",
      "Epoch 1:  32%|███▏      | 95/296 [00:22<00:47,  4.25it/s, v_num=0, train_loss=2.770]\n",
      "Epoch 1:  32%|███▏      | 96/296 [00:22<00:47,  4.25it/s, v_num=0, train_loss=2.390]\n",
      "Epoch 1:  33%|███▎      | 97/296 [00:22<00:46,  4.25it/s, v_num=0, train_loss=2.590]\n",
      "Epoch 1:  33%|███▎      | 98/296 [00:23<00:46,  4.25it/s, v_num=0, train_loss=2.860]\n",
      "Epoch 1:  33%|███▎      | 99/296 [00:23<00:46,  4.26it/s, v_num=0, train_loss=2.950]\n",
      "Epoch 1:  34%|███▍      | 100/296 [00:23<00:46,  4.26it/s, v_num=0, train_loss=2.160]\n",
      "Epoch 1:  34%|███▍      | 101/296 [00:23<00:45,  4.26it/s, v_num=0, train_loss=2.920]\n",
      "Epoch 1:  34%|███▍      | 102/296 [00:23<00:45,  4.26it/s, v_num=0, train_loss=2.680]\n",
      "Epoch 1:  35%|███▍      | 103/296 [00:24<00:45,  4.26it/s, v_num=0, train_loss=2.980]\n",
      "Epoch 1:  35%|███▌      | 104/296 [00:24<00:45,  4.26it/s, v_num=0, train_loss=2.440]\n",
      "Epoch 1:  35%|███▌      | 105/296 [00:24<00:44,  4.26it/s, v_num=0, train_loss=2.560]\n",
      "Epoch 1:  36%|███▌      | 106/296 [00:24<00:44,  4.25it/s, v_num=0, train_loss=2.320]\n",
      "Epoch 1:  36%|███▌      | 107/296 [00:25<00:44,  4.25it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 1:  36%|███▋      | 108/296 [00:25<00:44,  4.25it/s, v_num=0, train_loss=2.160]\n",
      "Epoch 1:  37%|███▋      | 109/296 [00:25<00:43,  4.25it/s, v_num=0, train_loss=2.350]\n",
      "Epoch 1:  37%|███▋      | 110/296 [00:25<00:43,  4.25it/s, v_num=0, train_loss=2.590]\n",
      "Epoch 1:  38%|███▊      | 111/296 [00:26<00:43,  4.25it/s, v_num=0, train_loss=2.800]\n",
      "Epoch 1:  38%|███▊      | 112/296 [00:26<00:43,  4.26it/s, v_num=0, train_loss=2.560]\n",
      "Epoch 1:  38%|███▊      | 113/296 [00:26<00:42,  4.26it/s, v_num=0, train_loss=2.230]\n",
      "Epoch 1:  39%|███▊      | 114/296 [00:26<00:42,  4.26it/s, v_num=0, train_loss=2.340]\n",
      "Epoch 1:  39%|███▉      | 115/296 [00:27<00:42,  4.26it/s, v_num=0, train_loss=2.460]\n",
      "Epoch 1:  39%|███▉      | 116/296 [00:27<00:42,  4.26it/s, v_num=0, train_loss=2.670]\n",
      "Epoch 1:  40%|███▉      | 117/296 [00:27<00:42,  4.26it/s, v_num=0, train_loss=3.390]\n",
      "Epoch 1:  40%|███▉      | 118/296 [00:27<00:41,  4.26it/s, v_num=0, train_loss=2.410]\n",
      "Epoch 1:  40%|████      | 119/296 [00:27<00:41,  4.26it/s, v_num=0, train_loss=2.860]\n",
      "Epoch 1:  41%|████      | 120/296 [00:28<00:41,  4.26it/s, v_num=0, train_loss=2.470]\n",
      "Epoch 1:  41%|████      | 121/296 [00:28<00:41,  4.26it/s, v_num=0, train_loss=2.590]\n",
      "Epoch 1:  41%|████      | 122/296 [00:28<00:40,  4.26it/s, v_num=0, train_loss=2.580]\n",
      "Epoch 1:  42%|████▏     | 123/296 [00:28<00:40,  4.27it/s, v_num=0, train_loss=2.590]\n",
      "Epoch 1:  42%|████▏     | 124/296 [00:29<00:40,  4.27it/s, v_num=0, train_loss=2.700]\n",
      "Epoch 1:  42%|████▏     | 125/296 [00:29<00:40,  4.27it/s, v_num=0, train_loss=2.950]\n",
      "Epoch 1:  43%|████▎     | 126/296 [00:29<00:39,  4.26it/s, v_num=0, train_loss=2.420]\n",
      "Epoch 1:  43%|████▎     | 127/296 [00:29<00:39,  4.26it/s, v_num=0, train_loss=2.740]\n",
      "Epoch 1:  43%|████▎     | 128/296 [00:30<00:39,  4.26it/s, v_num=0, train_loss=2.360]\n",
      "Epoch 1:  44%|████▎     | 129/296 [00:30<00:39,  4.26it/s, v_num=0, train_loss=3.040]\n",
      "Epoch 1:  44%|████▍     | 130/296 [00:30<00:38,  4.26it/s, v_num=0, train_loss=2.430]\n",
      "Epoch 1:  44%|████▍     | 131/296 [00:30<00:38,  4.26it/s, v_num=0, train_loss=2.820]\n",
      "Epoch 1:  45%|████▍     | 132/296 [00:30<00:38,  4.26it/s, v_num=0, train_loss=2.920]\n",
      "Epoch 1:  45%|████▍     | 133/296 [00:31<00:38,  4.26it/s, v_num=0, train_loss=2.750]\n",
      "Epoch 1:  45%|████▌     | 134/296 [00:31<00:37,  4.26it/s, v_num=0, train_loss=3.130]\n",
      "Epoch 1:  46%|████▌     | 135/296 [00:31<00:37,  4.27it/s, v_num=0, train_loss=2.740]\n",
      "Epoch 1:  46%|████▌     | 136/296 [00:31<00:37,  4.27it/s, v_num=0, train_loss=2.670]\n",
      "Epoch 1:  46%|████▋     | 137/296 [00:32<00:37,  4.27it/s, v_num=0, train_loss=3.060]\n",
      "Epoch 1:  47%|████▋     | 138/296 [00:32<00:37,  4.27it/s, v_num=0, train_loss=3.070]\n",
      "Epoch 1:  47%|████▋     | 139/296 [00:32<00:36,  4.27it/s, v_num=0, train_loss=2.830]\n",
      "Epoch 1:  47%|████▋     | 140/296 [00:32<00:36,  4.27it/s, v_num=0, train_loss=3.010]\n",
      "Epoch 1:  48%|████▊     | 141/296 [00:33<00:36,  4.27it/s, v_num=0, train_loss=3.160]\n",
      "Epoch 1:  48%|████▊     | 142/296 [00:33<00:36,  4.27it/s, v_num=0, train_loss=2.460]\n",
      "Epoch 1:  48%|████▊     | 143/296 [00:33<00:35,  4.27it/s, v_num=0, train_loss=2.700]\n",
      "Epoch 1:  49%|████▊     | 144/296 [00:33<00:35,  4.27it/s, v_num=0, train_loss=2.550]\n",
      "Epoch 1:  49%|████▉     | 145/296 [00:33<00:35,  4.27it/s, v_num=0, train_loss=2.870]\n",
      "Epoch 1:  49%|████▉     | 146/296 [00:34<00:35,  4.28it/s, v_num=0, train_loss=2.630]\n",
      "Epoch 1:  50%|████▉     | 147/296 [00:34<00:34,  4.28it/s, v_num=0, train_loss=2.680]\n",
      "Epoch 1:  50%|█████     | 148/296 [00:34<00:34,  4.28it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 1:  50%|█████     | 149/296 [00:34<00:34,  4.28it/s, v_num=0, train_loss=2.810]\n",
      "Epoch 1:  51%|█████     | 150/296 [00:35<00:34,  4.27it/s, v_num=0, train_loss=3.050]\n",
      "Epoch 1:  51%|█████     | 151/296 [00:35<00:33,  4.27it/s, v_num=0, train_loss=2.890]\n",
      "Epoch 1:  51%|█████▏    | 152/296 [00:35<00:33,  4.26it/s, v_num=0, train_loss=2.620]\n",
      "Epoch 1:  52%|█████▏    | 153/296 [00:35<00:33,  4.26it/s, v_num=0, train_loss=2.950]\n",
      "Epoch 1:  52%|█████▏    | 154/296 [00:36<00:33,  4.27it/s, v_num=0, train_loss=2.870]\n",
      "Epoch 1:  52%|█████▏    | 155/296 [00:36<00:33,  4.27it/s, v_num=0, train_loss=2.590]\n",
      "Epoch 1:  53%|█████▎    | 156/296 [00:36<00:32,  4.27it/s, v_num=0, train_loss=2.500]\n",
      "Epoch 1:  53%|█████▎    | 157/296 [00:36<00:32,  4.27it/s, v_num=0, train_loss=2.640]\n",
      "Epoch 1:  53%|█████▎    | 158/296 [00:37<00:32,  4.27it/s, v_num=0, train_loss=2.180]\n",
      "Epoch 1:  54%|█████▎    | 159/296 [00:37<00:32,  4.27it/s, v_num=0, train_loss=2.820]\n",
      "Epoch 1:  54%|█████▍    | 160/296 [00:37<00:31,  4.27it/s, v_num=0, train_loss=2.560]\n",
      "Epoch 1:  54%|█████▍    | 161/296 [00:37<00:31,  4.27it/s, v_num=0, train_loss=2.970]\n",
      "Epoch 1:  55%|█████▍    | 162/296 [00:37<00:31,  4.27it/s, v_num=0, train_loss=2.790]\n",
      "Epoch 1:  55%|█████▌    | 163/296 [00:38<00:31,  4.27it/s, v_num=0, train_loss=2.660]\n",
      "Epoch 1:  55%|█████▌    | 164/296 [00:38<00:30,  4.27it/s, v_num=0, train_loss=2.710]\n",
      "Epoch 1:  56%|█████▌    | 165/296 [00:38<00:30,  4.27it/s, v_num=0, train_loss=2.280]\n",
      "Epoch 1:  56%|█████▌    | 166/296 [00:38<00:30,  4.27it/s, v_num=0, train_loss=2.510]\n",
      "Epoch 1:  56%|█████▋    | 167/296 [00:39<00:30,  4.27it/s, v_num=0, train_loss=2.330]\n",
      "Epoch 1:  57%|█████▋    | 168/296 [00:39<00:29,  4.28it/s, v_num=0, train_loss=2.410]\n",
      "Epoch 1:  57%|█████▋    | 169/296 [00:39<00:29,  4.28it/s, v_num=0, train_loss=2.740]\n",
      "Epoch 1:  57%|█████▋    | 170/296 [00:39<00:29,  4.28it/s, v_num=0, train_loss=3.100]\n",
      "Epoch 1:  58%|█████▊    | 171/296 [00:39<00:29,  4.28it/s, v_num=0, train_loss=2.810]\n",
      "Epoch 1:  58%|█████▊    | 172/296 [00:40<00:28,  4.28it/s, v_num=0, train_loss=2.800]\n",
      "Epoch 1:  58%|█████▊    | 173/296 [00:40<00:28,  4.27it/s, v_num=0, train_loss=2.540]\n",
      "Epoch 1:  59%|█████▉    | 174/296 [00:40<00:28,  4.27it/s, v_num=0, train_loss=2.550]\n",
      "Epoch 1:  59%|█████▉    | 175/296 [00:40<00:28,  4.27it/s, v_num=0, train_loss=2.390]\n",
      "Epoch 1:  59%|█████▉    | 176/296 [00:41<00:28,  4.27it/s, v_num=0, train_loss=2.520]\n",
      "Epoch 1:  60%|█████▉    | 177/296 [00:41<00:27,  4.27it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 1:  60%|██████    | 178/296 [00:41<00:27,  4.28it/s, v_num=0, train_loss=2.800]\n",
      "Epoch 1:  60%|██████    | 179/296 [00:41<00:27,  4.28it/s, v_num=0, train_loss=3.110]\n",
      "Epoch 1:  61%|██████    | 180/296 [00:42<00:27,  4.28it/s, v_num=0, train_loss=2.490]\n",
      "Epoch 1:  61%|██████    | 181/296 [00:42<00:26,  4.28it/s, v_num=0, train_loss=3.250]\n",
      "Epoch 1:  61%|██████▏   | 182/296 [00:42<00:26,  4.28it/s, v_num=0, train_loss=2.940]\n",
      "Epoch 1:  62%|██████▏   | 183/296 [00:42<00:26,  4.28it/s, v_num=0, train_loss=3.080]\n",
      "Epoch 1:  62%|██████▏   | 184/296 [00:43<00:26,  4.28it/s, v_num=0, train_loss=2.820]\n",
      "Epoch 1:  62%|██████▎   | 185/296 [00:43<00:25,  4.28it/s, v_num=0, train_loss=2.700]\n",
      "Epoch 1:  63%|██████▎   | 186/296 [00:43<00:25,  4.28it/s, v_num=0, train_loss=2.540]\n",
      "Epoch 1:  63%|██████▎   | 187/296 [00:43<00:25,  4.28it/s, v_num=0, train_loss=2.990]\n",
      "Epoch 1:  64%|██████▎   | 188/296 [00:43<00:25,  4.28it/s, v_num=0, train_loss=3.030]\n",
      "Epoch 1:  64%|██████▍   | 189/296 [00:44<00:25,  4.28it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 1:  64%|██████▍   | 190/296 [00:44<00:24,  4.28it/s, v_num=0, train_loss=2.820]\n",
      "Epoch 1:  65%|██████▍   | 191/296 [00:44<00:24,  4.28it/s, v_num=0, train_loss=3.070]\n",
      "Epoch 1:  65%|██████▍   | 192/296 [00:44<00:24,  4.28it/s, v_num=0, train_loss=2.630]\n",
      "Epoch 1:  65%|██████▌   | 193/296 [00:45<00:24,  4.28it/s, v_num=0, train_loss=2.900]\n",
      "Epoch 1:  66%|██████▌   | 194/296 [00:45<00:23,  4.28it/s, v_num=0, train_loss=2.770]\n",
      "Epoch 1:  66%|██████▌   | 195/296 [00:45<00:23,  4.28it/s, v_num=0, train_loss=2.450]\n",
      "Epoch 1:  66%|██████▌   | 196/296 [00:45<00:23,  4.28it/s, v_num=0, train_loss=2.610]\n",
      "Epoch 1:  67%|██████▋   | 197/296 [00:46<00:23,  4.28it/s, v_num=0, train_loss=2.710]\n",
      "Epoch 1:  67%|██████▋   | 198/296 [00:46<00:22,  4.28it/s, v_num=0, train_loss=2.890]\n",
      "Epoch 1:  67%|██████▋   | 199/296 [00:46<00:22,  4.28it/s, v_num=0, train_loss=2.850]\n",
      "Epoch 1:  68%|██████▊   | 200/296 [00:46<00:22,  4.28it/s, v_num=0, train_loss=3.210]\n",
      "Epoch 1:  68%|██████▊   | 201/296 [00:46<00:22,  4.28it/s, v_num=0, train_loss=2.670]\n",
      "Epoch 1:  68%|██████▊   | 202/296 [00:47<00:21,  4.28it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 1:  69%|██████▊   | 203/296 [00:47<00:21,  4.28it/s, v_num=0, train_loss=2.340]\n",
      "Epoch 1:  69%|██████▉   | 204/296 [00:47<00:21,  4.28it/s, v_num=0, train_loss=2.800]\n",
      "Epoch 1:  69%|██████▉   | 205/296 [00:47<00:21,  4.28it/s, v_num=0, train_loss=2.760]\n",
      "Epoch 1:  70%|██████▉   | 206/296 [00:48<00:21,  4.28it/s, v_num=0, train_loss=3.020]\n",
      "Epoch 1:  70%|██████▉   | 207/296 [00:48<00:20,  4.28it/s, v_num=0, train_loss=2.690]\n",
      "Epoch 1:  70%|███████   | 208/296 [00:48<00:20,  4.29it/s, v_num=0, train_loss=2.820]\n",
      "Epoch 1:  71%|███████   | 209/296 [00:48<00:20,  4.29it/s, v_num=0, train_loss=3.050]\n",
      "Epoch 1:  71%|███████   | 210/296 [00:48<00:20,  4.29it/s, v_num=0, train_loss=2.810]\n",
      "Epoch 1:  71%|███████▏  | 211/296 [00:49<00:19,  4.29it/s, v_num=0, train_loss=2.890]\n",
      "Epoch 1:  72%|███████▏  | 212/296 [00:49<00:19,  4.29it/s, v_num=0, train_loss=2.280]\n",
      "Epoch 1:  72%|███████▏  | 213/296 [00:49<00:19,  4.29it/s, v_num=0, train_loss=2.830]\n",
      "Epoch 1:  72%|███████▏  | 214/296 [00:49<00:19,  4.29it/s, v_num=0, train_loss=2.680]\n",
      "Epoch 1:  73%|███████▎  | 215/296 [00:50<00:18,  4.29it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 1:  73%|███████▎  | 216/296 [00:50<00:18,  4.29it/s, v_num=0, train_loss=2.740]\n",
      "Epoch 1:  73%|███████▎  | 217/296 [00:50<00:18,  4.29it/s, v_num=0, train_loss=2.380]\n",
      "Epoch 1:  74%|███████▎  | 218/296 [00:50<00:18,  4.29it/s, v_num=0, train_loss=3.000]\n",
      "Epoch 1:  74%|███████▍  | 219/296 [00:51<00:17,  4.29it/s, v_num=0, train_loss=2.460]\n",
      "Epoch 1:  74%|███████▍  | 220/296 [00:51<00:17,  4.29it/s, v_num=0, train_loss=2.310]\n",
      "Epoch 1:  75%|███████▍  | 221/296 [00:51<00:17,  4.28it/s, v_num=0, train_loss=3.370]\n",
      "Epoch 1:  75%|███████▌  | 222/296 [00:51<00:17,  4.28it/s, v_num=0, train_loss=2.950]\n",
      "Epoch 1:  75%|███████▌  | 223/296 [00:52<00:17,  4.28it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 1:  76%|███████▌  | 224/296 [00:52<00:16,  4.28it/s, v_num=0, train_loss=3.130]\n",
      "Epoch 1:  76%|███████▌  | 225/296 [00:52<00:16,  4.28it/s, v_num=0, train_loss=2.370]\n",
      "Epoch 1:  76%|███████▋  | 226/296 [00:52<00:16,  4.29it/s, v_num=0, train_loss=2.720]\n",
      "Epoch 1:  77%|███████▋  | 227/296 [00:52<00:16,  4.29it/s, v_num=0, train_loss=3.100]\n",
      "Epoch 1:  77%|███████▋  | 228/296 [00:53<00:15,  4.29it/s, v_num=0, train_loss=2.760]\n",
      "Epoch 1:  77%|███████▋  | 229/296 [00:53<00:15,  4.29it/s, v_num=0, train_loss=2.950]\n",
      "Epoch 1:  78%|███████▊  | 230/296 [00:53<00:15,  4.29it/s, v_num=0, train_loss=2.830]\n",
      "Epoch 1:  78%|███████▊  | 231/296 [00:53<00:15,  4.29it/s, v_num=0, train_loss=2.960]\n",
      "Epoch 1:  78%|███████▊  | 232/296 [00:54<00:14,  4.29it/s, v_num=0, train_loss=2.860]\n",
      "Epoch 1:  79%|███████▊  | 233/296 [00:54<00:14,  4.29it/s, v_num=0, train_loss=3.060]\n",
      "Epoch 1:  79%|███████▉  | 234/296 [00:54<00:14,  4.29it/s, v_num=0, train_loss=2.810]\n",
      "Epoch 1:  79%|███████▉  | 235/296 [00:54<00:14,  4.29it/s, v_num=0, train_loss=2.850]\n",
      "Epoch 1:  80%|███████▉  | 236/296 [00:55<00:13,  4.29it/s, v_num=0, train_loss=3.370]\n",
      "Epoch 1:  80%|████████  | 237/296 [00:55<00:13,  4.29it/s, v_num=0, train_loss=2.550]\n",
      "Epoch 1:  80%|████████  | 238/296 [00:55<00:13,  4.29it/s, v_num=0, train_loss=2.920]\n",
      "Epoch 1:  81%|████████  | 239/296 [00:55<00:13,  4.29it/s, v_num=0, train_loss=2.830]\n",
      "Epoch 1:  81%|████████  | 240/296 [00:55<00:13,  4.29it/s, v_num=0, train_loss=2.500]\n",
      "Epoch 1:  81%|████████▏ | 241/296 [00:56<00:12,  4.29it/s, v_num=0, train_loss=2.750]\n",
      "Epoch 1:  82%|████████▏ | 242/296 [00:56<00:12,  4.29it/s, v_num=0, train_loss=3.240]\n",
      "Epoch 1:  82%|████████▏ | 243/296 [00:56<00:12,  4.29it/s, v_num=0, train_loss=2.690]\n",
      "Epoch 1:  82%|████████▏ | 244/296 [00:56<00:12,  4.29it/s, v_num=0, train_loss=2.540]\n",
      "Epoch 1:  83%|████████▎ | 245/296 [00:57<00:11,  4.29it/s, v_num=0, train_loss=2.660]\n",
      "Epoch 1:  83%|████████▎ | 246/296 [00:57<00:11,  4.29it/s, v_num=0, train_loss=2.680]\n",
      "Epoch 1:  83%|████████▎ | 247/296 [00:57<00:11,  4.29it/s, v_num=0, train_loss=2.470]\n",
      "Epoch 1:  84%|████████▍ | 248/296 [00:57<00:11,  4.29it/s, v_num=0, train_loss=2.690]\n",
      "Epoch 1:  84%|████████▍ | 249/296 [00:58<00:10,  4.29it/s, v_num=0, train_loss=3.080]\n",
      "Epoch 1:  84%|████████▍ | 250/296 [00:58<00:10,  4.29it/s, v_num=0, train_loss=2.590]\n",
      "Epoch 1:  85%|████████▍ | 251/296 [00:58<00:10,  4.29it/s, v_num=0, train_loss=2.940]\n",
      "Epoch 1:  85%|████████▌ | 252/296 [00:58<00:10,  4.29it/s, v_num=0, train_loss=2.720]\n",
      "Epoch 1:  85%|████████▌ | 253/296 [00:58<00:10,  4.29it/s, v_num=0, train_loss=3.180]\n",
      "Epoch 1:  86%|████████▌ | 254/296 [00:59<00:09,  4.29it/s, v_num=0, train_loss=2.900]\n",
      "Epoch 1:  86%|████████▌ | 255/296 [00:59<00:09,  4.29it/s, v_num=0, train_loss=3.280]\n",
      "Epoch 1:  86%|████████▋ | 256/296 [00:59<00:09,  4.27it/s, v_num=0, train_loss=3.070]\n",
      "Epoch 1:  87%|████████▋ | 257/296 [01:00<00:09,  4.27it/s, v_num=0, train_loss=3.050]\n",
      "Epoch 1:  87%|████████▋ | 258/296 [01:00<00:08,  4.27it/s, v_num=0, train_loss=2.520]\n",
      "Epoch 1:  88%|████████▊ | 259/296 [01:00<00:08,  4.27it/s, v_num=0, train_loss=2.930]\n",
      "Epoch 1:  88%|████████▊ | 260/296 [01:00<00:08,  4.27it/s, v_num=0, train_loss=2.850]\n",
      "Epoch 1:  88%|████████▊ | 261/296 [01:01<00:08,  4.27it/s, v_num=0, train_loss=2.680]\n",
      "Epoch 1:  89%|████████▊ | 262/296 [01:01<00:07,  4.26it/s, v_num=0, train_loss=2.850]\n",
      "Epoch 1:  89%|████████▉ | 263/296 [01:01<00:07,  4.26it/s, v_num=0, train_loss=2.950]\n",
      "Epoch 1:  89%|████████▉ | 264/296 [01:01<00:07,  4.26it/s, v_num=0, train_loss=2.710]\n",
      "Epoch 1:  90%|████████▉ | 265/296 [01:02<00:07,  4.26it/s, v_num=0, train_loss=2.410]\n",
      "Epoch 1:  90%|████████▉ | 266/296 [01:02<00:07,  4.26it/s, v_num=0, train_loss=2.530]\n",
      "Epoch 1:  90%|█████████ | 267/296 [01:02<00:06,  4.26it/s, v_num=0, train_loss=2.580]\n",
      "Epoch 1:  91%|█████████ | 268/296 [01:02<00:06,  4.26it/s, v_num=0, train_loss=2.700]\n",
      "Epoch 1:  91%|█████████ | 269/296 [01:03<00:06,  4.26it/s, v_num=0, train_loss=2.230]\n",
      "Epoch 1:  91%|█████████ | 270/296 [01:03<00:06,  4.26it/s, v_num=0, train_loss=2.670]\n",
      "Epoch 1:  92%|█████████▏| 271/296 [01:03<00:05,  4.26it/s, v_num=0, train_loss=2.980]\n",
      "Epoch 1:  92%|█████████▏| 272/296 [01:03<00:05,  4.26it/s, v_num=0, train_loss=2.860]\n",
      "Epoch 1:  92%|█████████▏| 273/296 [01:04<00:05,  4.26it/s, v_num=0, train_loss=2.750]\n",
      "Epoch 1:  93%|█████████▎| 274/296 [01:04<00:05,  4.26it/s, v_num=0, train_loss=2.610]\n",
      "Epoch 1:  93%|█████████▎| 275/296 [01:04<00:04,  4.27it/s, v_num=0, train_loss=2.860]\n",
      "Epoch 1:  93%|█████████▎| 276/296 [01:04<00:04,  4.27it/s, v_num=0, train_loss=2.670]\n",
      "Epoch 1:  94%|█████████▎| 277/296 [01:04<00:04,  4.27it/s, v_num=0, train_loss=2.740]\n",
      "Epoch 1:  94%|█████████▍| 278/296 [01:05<00:04,  4.27it/s, v_num=0, train_loss=2.690]\n",
      "Epoch 1:  94%|█████████▍| 279/296 [01:05<00:03,  4.27it/s, v_num=0, train_loss=2.750]\n",
      "Epoch 1:  95%|█████████▍| 280/296 [01:05<00:03,  4.27it/s, v_num=0, train_loss=2.470]\n",
      "Epoch 1:  95%|█████████▍| 281/296 [01:05<00:03,  4.27it/s, v_num=0, train_loss=2.460]\n",
      "Epoch 1:  95%|█████████▌| 282/296 [01:06<00:03,  4.27it/s, v_num=0, train_loss=2.840]\n",
      "Epoch 1:  96%|█████████▌| 283/296 [01:06<00:03,  4.27it/s, v_num=0, train_loss=2.980]\n",
      "Epoch 1:  96%|█████████▌| 284/296 [01:06<00:02,  4.27it/s, v_num=0, train_loss=3.290]\n",
      "Epoch 1:  96%|█████████▋| 285/296 [01:06<00:02,  4.27it/s, v_num=0, train_loss=2.560]\n",
      "Epoch 1:  97%|█████████▋| 286/296 [01:06<00:02,  4.27it/s, v_num=0, train_loss=2.630]\n",
      "Epoch 1:  97%|█████████▋| 287/296 [01:07<00:02,  4.27it/s, v_num=0, train_loss=2.830]\n",
      "Epoch 1:  97%|█████████▋| 288/296 [01:07<00:01,  4.27it/s, v_num=0, train_loss=2.880]\n",
      "Epoch 1:  98%|█████████▊| 289/296 [01:07<00:01,  4.27it/s, v_num=0, train_loss=2.490]\n",
      "Epoch 1:  98%|█████████▊| 290/296 [01:07<00:01,  4.27it/s, v_num=0, train_loss=2.790]\n",
      "Epoch 1:  98%|█████████▊| 291/296 [01:08<00:01,  4.27it/s, v_num=0, train_loss=2.790]\n",
      "Epoch 1:  99%|█████████▊| 292/296 [01:08<00:00,  4.27it/s, v_num=0, train_loss=3.080]\n",
      "Epoch 1:  99%|█████████▉| 293/296 [01:08<00:00,  4.27it/s, v_num=0, train_loss=2.570]\n",
      "Epoch 1:  99%|█████████▉| 294/296 [01:08<00:00,  4.27it/s, v_num=0, train_loss=2.530]\n",
      "Epoch 1: 100%|█████████▉| 295/296 [01:09<00:00,  4.27it/s, v_num=0, train_loss=2.920]\n",
      "Epoch 1: 100%|██████████| 296/296 [01:09<00:00,  4.27it/s, v_num=0, train_loss=2.590]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4156085)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/davinci-1/home/abeatini/ray_results/TorchTrainer_2025-06-26_19-01-27/TorchTrainer_32cee_00000_0_2025-06-26_19-01-27/checkpoint_000001)\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 296/296 [01:10<00:00,  4.23it/s, v_num=0, train_loss=2.590]\n",
      "Epoch 2:   0%|          | 0/296 [00:00<?, ?it/s, v_num=0, train_loss=2.590]          \n",
      "Epoch 2:   0%|          | 1/296 [00:00<01:10,  4.17it/s, v_num=0, train_loss=2.450]\n",
      "Epoch 2:   1%|          | 2/296 [00:00<01:08,  4.28it/s, v_num=0, train_loss=2.260]\n",
      "Epoch 2:   1%|          | 3/296 [00:00<01:08,  4.30it/s, v_num=0, train_loss=2.240]\n",
      "Epoch 2:   1%|▏         | 4/296 [00:00<01:07,  4.32it/s, v_num=0, train_loss=1.940]\n",
      "Epoch 2:   2%|▏         | 5/296 [00:01<01:07,  4.33it/s, v_num=0, train_loss=2.030]\n",
      "Epoch 2:   2%|▏         | 6/296 [00:01<01:06,  4.34it/s, v_num=0, train_loss=2.090]\n",
      "Epoch 2:   2%|▏         | 7/296 [00:01<01:06,  4.35it/s, v_num=0, train_loss=2.280]\n",
      "Epoch 2:   3%|▎         | 8/296 [00:01<01:06,  4.35it/s, v_num=0, train_loss=2.390]\n",
      "Epoch 2:   3%|▎         | 9/296 [00:02<01:05,  4.35it/s, v_num=0, train_loss=2.220]\n",
      "Epoch 2:   3%|▎         | 10/296 [00:02<01:06,  4.29it/s, v_num=0, train_loss=2.380]\n",
      "Epoch 2:   4%|▎         | 11/296 [00:02<01:08,  4.19it/s, v_num=0, train_loss=2.100]\n",
      "Epoch 2:   4%|▍         | 12/296 [00:02<01:07,  4.21it/s, v_num=0, train_loss=2.090]\n",
      "Epoch 2:   4%|▍         | 13/296 [00:03<01:07,  4.22it/s, v_num=0, train_loss=2.130]\n",
      "Epoch 2:   5%|▍         | 14/296 [00:03<01:06,  4.23it/s, v_num=0, train_loss=2.020]\n",
      "Epoch 2:   5%|▌         | 15/296 [00:03<01:06,  4.24it/s, v_num=0, train_loss=2.340]\n",
      "Epoch 2:   5%|▌         | 16/296 [00:03<01:05,  4.25it/s, v_num=0, train_loss=1.910]\n",
      "Epoch 2:   6%|▌         | 17/296 [00:03<01:05,  4.26it/s, v_num=0, train_loss=1.920]\n",
      "Epoch 2:   6%|▌         | 18/296 [00:04<01:05,  4.26it/s, v_num=0, train_loss=1.820]\n",
      "Epoch 2:   6%|▋         | 19/296 [00:04<01:07,  4.09it/s, v_num=0, train_loss=2.260]\n",
      "Epoch 2:   7%|▋         | 20/296 [00:04<01:07,  4.11it/s, v_num=0, train_loss=2.190]\n",
      "Epoch 2:   7%|▋         | 21/296 [00:05<01:06,  4.12it/s, v_num=0, train_loss=2.050]\n",
      "Epoch 2:   7%|▋         | 22/296 [00:05<01:06,  4.13it/s, v_num=0, train_loss=2.020]\n",
      "Epoch 2:   8%|▊         | 23/296 [00:05<01:05,  4.14it/s, v_num=0, train_loss=2.020]\n",
      "Epoch 2:   8%|▊         | 24/296 [00:05<01:05,  4.14it/s, v_num=0, train_loss=2.090]\n",
      "Epoch 2:   8%|▊         | 25/296 [00:06<01:05,  4.15it/s, v_num=0, train_loss=2.090]\n",
      "Epoch 2:   9%|▉         | 26/296 [00:06<01:04,  4.16it/s, v_num=0, train_loss=1.900]\n",
      "Epoch 2:   9%|▉         | 27/296 [00:06<01:04,  4.17it/s, v_num=0, train_loss=2.030]\n",
      "Epoch 2:   9%|▉         | 28/296 [00:06<01:04,  4.18it/s, v_num=0, train_loss=2.380]\n",
      "Epoch 2:  10%|▉         | 29/296 [00:06<01:03,  4.18it/s, v_num=0, train_loss=2.670]\n",
      "Epoch 2:  10%|█         | 30/296 [00:07<01:03,  4.19it/s, v_num=0, train_loss=2.320]\n",
      "Epoch 2:  10%|█         | 31/296 [00:07<01:03,  4.20it/s, v_num=0, train_loss=2.170]\n",
      "Epoch 2:  11%|█         | 32/296 [00:07<01:02,  4.19it/s, v_num=0, train_loss=2.140]\n",
      "Epoch 2:  11%|█         | 33/296 [00:07<01:02,  4.20it/s, v_num=0, train_loss=1.460]\n",
      "Epoch 2:  11%|█▏        | 34/296 [00:08<01:02,  4.19it/s, v_num=0, train_loss=2.310]\n",
      "Epoch 2:  12%|█▏        | 35/296 [00:08<01:02,  4.20it/s, v_num=0, train_loss=2.270]\n",
      "Epoch 2:  12%|█▏        | 36/296 [00:08<01:01,  4.21it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 2:  12%|█▎        | 37/296 [00:08<01:01,  4.21it/s, v_num=0, train_loss=2.170]\n",
      "Epoch 2:  13%|█▎        | 38/296 [00:09<01:01,  4.22it/s, v_num=0, train_loss=2.210]\n",
      "Epoch 2:  13%|█▎        | 39/296 [00:09<01:00,  4.22it/s, v_num=0, train_loss=2.390]\n",
      "Epoch 2:  14%|█▎        | 40/296 [00:09<01:00,  4.23it/s, v_num=0, train_loss=1.960]\n",
      "Epoch 2:  14%|█▍        | 41/296 [00:09<01:00,  4.23it/s, v_num=0, train_loss=2.510]\n",
      "Epoch 2:  14%|█▍        | 42/296 [00:09<00:59,  4.23it/s, v_num=0, train_loss=2.060]\n",
      "Epoch 2:  15%|█▍        | 43/296 [00:10<00:59,  4.24it/s, v_num=0, train_loss=2.370]\n",
      "Epoch 2:  15%|█▍        | 44/296 [00:10<00:59,  4.24it/s, v_num=0, train_loss=2.000]\n",
      "Epoch 2:  15%|█▌        | 45/296 [00:10<00:59,  4.24it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 2:  16%|█▌        | 46/296 [00:10<00:58,  4.25it/s, v_num=0, train_loss=2.220]\n",
      "Epoch 2:  16%|█▌        | 47/296 [00:11<00:58,  4.25it/s, v_num=0, train_loss=2.270]\n",
      "Epoch 2:  16%|█▌        | 48/296 [00:11<00:58,  4.25it/s, v_num=0, train_loss=2.210]\n",
      "Epoch 2:  17%|█▋        | 49/296 [00:11<00:58,  4.26it/s, v_num=0, train_loss=1.770]\n",
      "Epoch 2:  17%|█▋        | 50/296 [00:11<00:57,  4.26it/s, v_num=0, train_loss=1.950]\n",
      "Epoch 2:  17%|█▋        | 51/296 [00:11<00:57,  4.26it/s, v_num=0, train_loss=2.260]\n",
      "Epoch 2:  18%|█▊        | 52/296 [00:12<00:57,  4.26it/s, v_num=0, train_loss=2.000]\n",
      "Epoch 2:  18%|█▊        | 53/296 [00:12<00:56,  4.27it/s, v_num=0, train_loss=2.390]\n",
      "Epoch 2:  18%|█▊        | 54/296 [00:12<00:56,  4.27it/s, v_num=0, train_loss=2.130]\n",
      "Epoch 2:  19%|█▊        | 55/296 [00:12<00:56,  4.26it/s, v_num=0, train_loss=1.980]\n",
      "Epoch 2:  19%|█▉        | 56/296 [00:13<00:56,  4.27it/s, v_num=0, train_loss=2.350]\n",
      "Epoch 2:  19%|█▉        | 57/296 [00:13<00:56,  4.25it/s, v_num=0, train_loss=2.230]\n",
      "Epoch 2:  20%|█▉        | 58/296 [00:13<00:55,  4.26it/s, v_num=0, train_loss=2.210]\n",
      "Epoch 2:  20%|█▉        | 59/296 [00:13<00:55,  4.26it/s, v_num=0, train_loss=1.840]\n",
      "Epoch 2:  20%|██        | 60/296 [00:14<00:55,  4.26it/s, v_num=0, train_loss=1.800]\n",
      "Epoch 2:  21%|██        | 61/296 [00:14<00:55,  4.26it/s, v_num=0, train_loss=2.460]\n",
      "Epoch 2:  21%|██        | 62/296 [00:14<00:54,  4.26it/s, v_num=0, train_loss=1.970]\n",
      "Epoch 2:  21%|██▏       | 63/296 [00:14<00:54,  4.27it/s, v_num=0, train_loss=2.270]\n",
      "Epoch 2:  22%|██▏       | 64/296 [00:14<00:54,  4.27it/s, v_num=0, train_loss=2.200]\n",
      "Epoch 2:  22%|██▏       | 65/296 [00:15<00:54,  4.27it/s, v_num=0, train_loss=2.400]\n",
      "Epoch 2:  22%|██▏       | 66/296 [00:15<00:53,  4.27it/s, v_num=0, train_loss=2.140]\n",
      "Epoch 2:  23%|██▎       | 67/296 [00:15<00:53,  4.27it/s, v_num=0, train_loss=1.860]\n",
      "Epoch 2:  23%|██▎       | 68/296 [00:15<00:53,  4.28it/s, v_num=0, train_loss=2.080]\n",
      "Epoch 2:  23%|██▎       | 69/296 [00:16<00:53,  4.28it/s, v_num=0, train_loss=2.190]\n",
      "Epoch 2:  24%|██▎       | 70/296 [00:16<00:52,  4.28it/s, v_num=0, train_loss=2.120]\n",
      "Epoch 2:  24%|██▍       | 71/296 [00:16<00:52,  4.28it/s, v_num=0, train_loss=2.310]\n",
      "Epoch 2:  24%|██▍       | 72/296 [00:16<00:52,  4.28it/s, v_num=0, train_loss=1.990]\n",
      "Epoch 2:  25%|██▍       | 73/296 [00:17<00:52,  4.28it/s, v_num=0, train_loss=1.560]\n",
      "Epoch 2:  25%|██▌       | 74/296 [00:17<00:51,  4.29it/s, v_num=0, train_loss=2.140]\n",
      "Epoch 2:  25%|██▌       | 75/296 [00:17<00:51,  4.29it/s, v_num=0, train_loss=2.200]\n",
      "Epoch 2:  26%|██▌       | 76/296 [00:17<00:51,  4.29it/s, v_num=0, train_loss=2.110]\n",
      "Epoch 2:  26%|██▌       | 77/296 [00:17<00:51,  4.29it/s, v_num=0, train_loss=2.350]\n",
      "Epoch 2:  26%|██▋       | 78/296 [00:18<00:50,  4.29it/s, v_num=0, train_loss=2.070]\n",
      "Epoch 2:  27%|██▋       | 79/296 [00:18<00:50,  4.29it/s, v_num=0, train_loss=2.370]\n",
      "Epoch 2:  27%|██▋       | 80/296 [00:18<00:50,  4.29it/s, v_num=0, train_loss=2.300]\n",
      "Epoch 2:  27%|██▋       | 81/296 [00:18<00:50,  4.29it/s, v_num=0, train_loss=2.250]\n",
      "Epoch 2:  28%|██▊       | 82/296 [00:19<00:49,  4.29it/s, v_num=0, train_loss=2.170]\n",
      "Epoch 2:  28%|██▊       | 83/296 [00:19<00:49,  4.29it/s, v_num=0, train_loss=2.650]\n",
      "Epoch 2:  28%|██▊       | 84/296 [00:19<00:49,  4.29it/s, v_num=0, train_loss=2.280]\n",
      "Epoch 2:  29%|██▊       | 85/296 [00:19<00:49,  4.29it/s, v_num=0, train_loss=2.550]\n",
      "Epoch 2:  29%|██▉       | 86/296 [00:20<00:48,  4.30it/s, v_num=0, train_loss=2.490]\n",
      "Epoch 2:  29%|██▉       | 87/296 [00:20<00:48,  4.30it/s, v_num=0, train_loss=2.270]\n",
      "Epoch 2:  30%|██▉       | 88/296 [00:20<00:48,  4.30it/s, v_num=0, train_loss=2.510]\n",
      "Epoch 2:  30%|███       | 89/296 [00:20<00:48,  4.30it/s, v_num=0, train_loss=2.000]\n",
      "Epoch 2:  30%|███       | 90/296 [00:20<00:47,  4.30it/s, v_num=0, train_loss=2.170]\n",
      "Epoch 2:  31%|███       | 91/296 [00:21<00:47,  4.30it/s, v_num=0, train_loss=2.210]\n",
      "Epoch 2:  31%|███       | 92/296 [00:21<00:47,  4.30it/s, v_num=0, train_loss=2.270]\n",
      "Epoch 2:  31%|███▏      | 93/296 [00:21<00:47,  4.30it/s, v_num=0, train_loss=2.370]\n",
      "Epoch 2:  32%|███▏      | 94/296 [00:21<00:46,  4.30it/s, v_num=0, train_loss=2.440]\n",
      "Epoch 2:  32%|███▏      | 95/296 [00:22<00:46,  4.30it/s, v_num=0, train_loss=2.400]\n",
      "Epoch 2:  32%|███▏      | 96/296 [00:22<00:46,  4.30it/s, v_num=0, train_loss=2.290]\n",
      "Epoch 2:  33%|███▎      | 97/296 [00:22<00:46,  4.31it/s, v_num=0, train_loss=2.310]\n",
      "Epoch 2:  33%|███▎      | 98/296 [00:22<00:45,  4.31it/s, v_num=0, train_loss=2.230]\n",
      "Epoch 2:  33%|███▎      | 99/296 [00:22<00:45,  4.31it/s, v_num=0, train_loss=2.030]\n",
      "Epoch 2:  34%|███▍      | 100/296 [00:23<00:45,  4.31it/s, v_num=0, train_loss=2.580]\n",
      "Epoch 2:  34%|███▍      | 101/296 [00:23<00:45,  4.31it/s, v_num=0, train_loss=2.120]\n",
      "Epoch 2:  34%|███▍      | 102/296 [00:23<00:45,  4.31it/s, v_num=0, train_loss=2.250]\n",
      "Epoch 2:  35%|███▍      | 103/296 [00:23<00:44,  4.31it/s, v_num=0, train_loss=2.280]\n",
      "Epoch 2:  35%|███▌      | 104/296 [00:24<00:44,  4.31it/s, v_num=0, train_loss=1.950]\n",
      "Epoch 2:  35%|███▌      | 105/296 [00:24<00:44,  4.31it/s, v_num=0, train_loss=1.860]\n",
      "Epoch 2:  36%|███▌      | 106/296 [00:24<00:44,  4.31it/s, v_num=0, train_loss=2.280]\n",
      "Epoch 2:  36%|███▌      | 107/296 [00:24<00:43,  4.31it/s, v_num=0, train_loss=2.130]\n",
      "Epoch 2:  36%|███▋      | 108/296 [00:25<00:43,  4.31it/s, v_num=0, train_loss=2.290]\n",
      "Epoch 2:  37%|███▋      | 109/296 [00:25<00:43,  4.31it/s, v_num=0, train_loss=2.410]\n",
      "Epoch 2:  37%|███▋      | 110/296 [00:25<00:43,  4.31it/s, v_num=0, train_loss=2.270]\n",
      "Epoch 2:  38%|███▊      | 111/296 [00:25<00:42,  4.31it/s, v_num=0, train_loss=2.180]\n",
      "Epoch 2:  38%|███▊      | 112/296 [00:25<00:42,  4.31it/s, v_num=0, train_loss=2.360]\n",
      "Epoch 2:  38%|███▊      | 113/296 [00:26<00:42,  4.31it/s, v_num=0, train_loss=1.990]\n",
      "Epoch 2:  39%|███▊      | 114/296 [00:26<00:42,  4.31it/s, v_num=0, train_loss=2.430]\n",
      "Epoch 2:  39%|███▉      | 115/296 [00:26<00:41,  4.31it/s, v_num=0, train_loss=2.510]\n",
      "Epoch 2:  39%|███▉      | 116/296 [00:26<00:41,  4.31it/s, v_num=0, train_loss=2.200]\n",
      "Epoch 2:  40%|███▉      | 117/296 [00:27<00:41,  4.31it/s, v_num=0, train_loss=2.160]\n",
      "Epoch 2:  40%|███▉      | 118/296 [00:27<00:41,  4.32it/s, v_num=0, train_loss=2.260]\n",
      "Epoch 2:  40%|████      | 119/296 [00:27<00:41,  4.32it/s, v_num=0, train_loss=2.000]\n",
      "Epoch 2:  41%|████      | 120/296 [00:27<00:40,  4.32it/s, v_num=0, train_loss=2.410]\n",
      "Epoch 2:  41%|████      | 121/296 [00:28<00:40,  4.32it/s, v_num=0, train_loss=2.140]\n",
      "Epoch 2:  41%|████      | 122/296 [00:28<00:40,  4.32it/s, v_num=0, train_loss=2.420]\n",
      "Epoch 2:  42%|████▏     | 123/296 [00:28<00:40,  4.32it/s, v_num=0, train_loss=2.350]\n",
      "Epoch 2:  42%|████▏     | 124/296 [00:28<00:39,  4.32it/s, v_num=0, train_loss=2.510]\n",
      "Epoch 2:  42%|████▏     | 125/296 [00:28<00:39,  4.32it/s, v_num=0, train_loss=2.570]\n",
      "Epoch 2:  43%|████▎     | 126/296 [00:29<00:39,  4.32it/s, v_num=0, train_loss=1.970]\n",
      "Epoch 2:  43%|████▎     | 127/296 [00:29<00:39,  4.32it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 2:  43%|████▎     | 128/296 [00:29<00:38,  4.32it/s, v_num=0, train_loss=2.250]\n",
      "Epoch 2:  44%|████▎     | 129/296 [00:29<00:38,  4.32it/s, v_num=0, train_loss=2.050]\n",
      "Epoch 2:  44%|████▍     | 130/296 [00:30<00:38,  4.32it/s, v_num=0, train_loss=2.450]\n",
      "Epoch 2:  44%|████▍     | 131/296 [00:30<00:38,  4.32it/s, v_num=0, train_loss=2.060]\n",
      "Epoch 2:  45%|████▍     | 132/296 [00:30<00:37,  4.32it/s, v_num=0, train_loss=2.200]\n",
      "Epoch 2:  45%|████▍     | 133/296 [00:30<00:37,  4.32it/s, v_num=0, train_loss=2.630]\n",
      "Epoch 2:  45%|████▌     | 134/296 [00:31<00:37,  4.32it/s, v_num=0, train_loss=2.570]\n",
      "Epoch 2:  46%|████▌     | 135/296 [00:31<00:37,  4.32it/s, v_num=0, train_loss=2.150]\n",
      "Epoch 2:  46%|████▌     | 136/296 [00:31<00:37,  4.32it/s, v_num=0, train_loss=2.030]\n",
      "Epoch 2:  46%|████▋     | 137/296 [00:31<00:36,  4.32it/s, v_num=0, train_loss=2.070]\n",
      "Epoch 2:  47%|████▋     | 138/296 [00:31<00:36,  4.32it/s, v_num=0, train_loss=2.420]\n",
      "Epoch 2:  47%|████▋     | 139/296 [00:32<00:36,  4.32it/s, v_num=0, train_loss=2.110]\n",
      "Epoch 2:  47%|████▋     | 140/296 [00:32<00:36,  4.32it/s, v_num=0, train_loss=2.010]\n",
      "Epoch 2:  48%|████▊     | 141/296 [00:32<00:35,  4.32it/s, v_num=0, train_loss=2.080]\n",
      "Epoch 2:  48%|████▊     | 142/296 [00:32<00:35,  4.32it/s, v_num=0, train_loss=2.410]\n",
      "Epoch 2:  48%|████▊     | 143/296 [00:33<00:35,  4.33it/s, v_num=0, train_loss=2.180]\n",
      "Epoch 2:  49%|████▊     | 144/296 [00:33<00:35,  4.33it/s, v_num=0, train_loss=2.200]\n",
      "Epoch 2:  49%|████▉     | 145/296 [00:33<00:34,  4.33it/s, v_num=0, train_loss=2.220]\n",
      "Epoch 2:  49%|████▉     | 146/296 [00:33<00:34,  4.33it/s, v_num=0, train_loss=2.240]\n",
      "Epoch 2:  50%|████▉     | 147/296 [00:33<00:34,  4.33it/s, v_num=0, train_loss=2.120]\n",
      "Epoch 2:  50%|█████     | 148/296 [00:34<00:34,  4.33it/s, v_num=0, train_loss=2.440]\n",
      "Epoch 2:  50%|█████     | 149/296 [00:34<00:33,  4.33it/s, v_num=0, train_loss=2.410]\n",
      "Epoch 2:  51%|█████     | 150/296 [00:34<00:33,  4.33it/s, v_num=0, train_loss=2.090]\n",
      "Epoch 2:  51%|█████     | 151/296 [00:34<00:33,  4.33it/s, v_num=0, train_loss=2.350]\n",
      "Epoch 2:  51%|█████▏    | 152/296 [00:35<00:33,  4.32it/s, v_num=0, train_loss=2.460]\n",
      "Epoch 2:  52%|█████▏    | 153/296 [00:35<00:33,  4.32it/s, v_num=0, train_loss=2.420]\n",
      "Epoch 2:  52%|█████▏    | 154/296 [00:35<00:32,  4.32it/s, v_num=0, train_loss=1.850]\n",
      "Epoch 2:  52%|█████▏    | 155/296 [00:35<00:32,  4.32it/s, v_num=0, train_loss=2.310]\n",
      "Epoch 2:  53%|█████▎    | 156/296 [00:36<00:32,  4.33it/s, v_num=0, train_loss=2.300]\n",
      "Epoch 2:  53%|█████▎    | 157/296 [00:36<00:32,  4.33it/s, v_num=0, train_loss=2.320]\n",
      "Epoch 2:  53%|█████▎    | 158/296 [00:36<00:31,  4.33it/s, v_num=0, train_loss=2.310]\n",
      "Epoch 2:  54%|█████▎    | 159/296 [00:36<00:31,  4.33it/s, v_num=0, train_loss=2.400]\n",
      "Epoch 2:  54%|█████▍    | 160/296 [00:36<00:31,  4.33it/s, v_num=0, train_loss=2.630]\n",
      "Epoch 2:  54%|█████▍    | 161/296 [00:37<00:31,  4.33it/s, v_num=0, train_loss=2.180]\n",
      "Epoch 2:  55%|█████▍    | 162/296 [00:37<00:30,  4.33it/s, v_num=0, train_loss=2.570]\n",
      "Epoch 2:  55%|█████▌    | 163/296 [00:37<00:30,  4.33it/s, v_num=0, train_loss=2.020]\n",
      "Epoch 2:  55%|█████▌    | 164/296 [00:37<00:30,  4.33it/s, v_num=0, train_loss=2.290]\n",
      "Epoch 2:  56%|█████▌    | 165/296 [00:38<00:30,  4.33it/s, v_num=0, train_loss=2.300]\n",
      "Epoch 2:  56%|█████▌    | 166/296 [00:38<00:30,  4.33it/s, v_num=0, train_loss=2.500]\n",
      "Epoch 2:  56%|█████▋    | 167/296 [00:38<00:29,  4.33it/s, v_num=0, train_loss=2.280]\n",
      "Epoch 2:  57%|█████▋    | 168/296 [00:38<00:29,  4.33it/s, v_num=0, train_loss=2.430]\n",
      "Epoch 2:  57%|█████▋    | 169/296 [00:39<00:29,  4.33it/s, v_num=0, train_loss=2.250]\n",
      "Epoch 2:  57%|█████▋    | 170/296 [00:39<00:29,  4.33it/s, v_num=0, train_loss=2.400]\n",
      "Epoch 2:  58%|█████▊    | 171/296 [00:39<00:28,  4.33it/s, v_num=0, train_loss=2.180]\n",
      "Epoch 2:  58%|█████▊    | 172/296 [00:39<00:28,  4.33it/s, v_num=0, train_loss=2.130]\n",
      "Epoch 2:  58%|█████▊    | 173/296 [00:39<00:28,  4.33it/s, v_num=0, train_loss=2.080]\n",
      "Epoch 2:  59%|█████▉    | 174/296 [00:40<00:28,  4.33it/s, v_num=0, train_loss=2.200]\n",
      "Epoch 2:  59%|█████▉    | 175/296 [00:40<00:27,  4.33it/s, v_num=0, train_loss=2.320]\n",
      "Epoch 2:  59%|█████▉    | 176/296 [00:40<00:27,  4.33it/s, v_num=0, train_loss=2.630]\n",
      "Epoch 2:  60%|█████▉    | 177/296 [00:40<00:27,  4.33it/s, v_num=0, train_loss=2.320]\n",
      "Epoch 2:  60%|██████    | 178/296 [00:41<00:27,  4.33it/s, v_num=0, train_loss=2.980]\n",
      "Epoch 2:  60%|██████    | 179/296 [00:41<00:27,  4.33it/s, v_num=0, train_loss=2.440]\n",
      "Epoch 2:  61%|██████    | 180/296 [00:41<00:26,  4.33it/s, v_num=0, train_loss=2.520]\n",
      "Epoch 2:  61%|██████    | 181/296 [00:41<00:26,  4.33it/s, v_num=0, train_loss=2.320]\n",
      "Epoch 2:  61%|██████▏   | 182/296 [00:41<00:26,  4.33it/s, v_num=0, train_loss=2.220]\n",
      "Epoch 2:  62%|██████▏   | 183/296 [00:42<00:26,  4.33it/s, v_num=0, train_loss=2.220]\n",
      "Epoch 2:  62%|██████▏   | 184/296 [00:42<00:25,  4.33it/s, v_num=0, train_loss=2.300]\n",
      "Epoch 2:  62%|██████▎   | 185/296 [00:42<00:25,  4.33it/s, v_num=0, train_loss=2.680]\n",
      "Epoch 2:  63%|██████▎   | 186/296 [00:42<00:25,  4.33it/s, v_num=0, train_loss=2.200]\n",
      "Epoch 2:  63%|██████▎   | 187/296 [00:43<00:25,  4.33it/s, v_num=0, train_loss=2.260]\n",
      "Epoch 2:  64%|██████▎   | 188/296 [00:43<00:24,  4.33it/s, v_num=0, train_loss=2.320]\n",
      "Epoch 2:  64%|██████▍   | 189/296 [00:43<00:24,  4.33it/s, v_num=0, train_loss=2.430]\n",
      "Epoch 2:  64%|██████▍   | 190/296 [00:43<00:24,  4.33it/s, v_num=0, train_loss=2.320]\n",
      "Epoch 2:  65%|██████▍   | 191/296 [00:44<00:24,  4.34it/s, v_num=0, train_loss=2.440]\n",
      "Epoch 2:  65%|██████▍   | 192/296 [00:44<00:23,  4.34it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 2:  65%|██████▌   | 193/296 [00:44<00:23,  4.34it/s, v_num=0, train_loss=2.260]\n",
      "Epoch 2:  66%|██████▌   | 194/296 [00:44<00:23,  4.34it/s, v_num=0, train_loss=2.530]\n",
      "Epoch 2:  66%|██████▌   | 195/296 [00:45<00:23,  4.33it/s, v_num=0, train_loss=2.760]\n",
      "Epoch 2:  66%|██████▌   | 196/296 [00:45<00:23,  4.33it/s, v_num=0, train_loss=2.310]\n",
      "Epoch 2:  67%|██████▋   | 197/296 [00:45<00:22,  4.33it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 2:  67%|██████▋   | 198/296 [00:45<00:22,  4.33it/s, v_num=0, train_loss=2.350]\n",
      "Epoch 2:  67%|██████▋   | 199/296 [00:45<00:22,  4.33it/s, v_num=0, train_loss=2.570]\n",
      "Epoch 2:  68%|██████▊   | 200/296 [00:46<00:22,  4.33it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 2:  68%|██████▊   | 201/296 [00:46<00:21,  4.33it/s, v_num=0, train_loss=2.540]\n",
      "Epoch 2:  68%|██████▊   | 202/296 [00:46<00:21,  4.33it/s, v_num=0, train_loss=2.010]\n",
      "Epoch 2:  69%|██████▊   | 203/296 [00:46<00:21,  4.33it/s, v_num=0, train_loss=2.360]\n",
      "Epoch 2:  69%|██████▉   | 204/296 [00:47<00:21,  4.33it/s, v_num=0, train_loss=2.380]\n",
      "Epoch 2:  69%|██████▉   | 205/296 [00:47<00:21,  4.32it/s, v_num=0, train_loss=2.280]\n",
      "Epoch 2:  70%|██████▉   | 206/296 [00:47<00:20,  4.32it/s, v_num=0, train_loss=2.530]\n",
      "Epoch 2:  70%|██████▉   | 207/296 [00:47<00:20,  4.32it/s, v_num=0, train_loss=2.180]\n",
      "Epoch 2:  70%|███████   | 208/296 [00:48<00:20,  4.30it/s, v_num=0, train_loss=2.250]\n",
      "Epoch 2:  71%|███████   | 209/296 [00:48<00:20,  4.30it/s, v_num=0, train_loss=2.590]\n",
      "Epoch 2:  71%|███████   | 210/296 [00:48<00:20,  4.30it/s, v_num=0, train_loss=2.450]\n",
      "Epoch 2:  71%|███████▏  | 211/296 [00:49<00:19,  4.27it/s, v_num=0, train_loss=2.120]\n",
      "Epoch 2:  72%|███████▏  | 212/296 [00:49<00:19,  4.27it/s, v_num=0, train_loss=2.410]\n",
      "Epoch 2:  72%|███████▏  | 213/296 [00:49<00:19,  4.28it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 2:  72%|███████▏  | 214/296 [00:50<00:19,  4.28it/s, v_num=0, train_loss=2.350]\n",
      "Epoch 2:  73%|███████▎  | 215/296 [00:50<00:19,  4.26it/s, v_num=0, train_loss=2.450]\n",
      "Epoch 2:  73%|███████▎  | 216/296 [00:50<00:18,  4.26it/s, v_num=0, train_loss=2.280]\n",
      "Epoch 2:  73%|███████▎  | 217/296 [00:50<00:18,  4.26it/s, v_num=0, train_loss=2.300]\n",
      "Epoch 2:  74%|███████▎  | 218/296 [00:51<00:18,  4.26it/s, v_num=0, train_loss=2.430]\n",
      "Epoch 2:  74%|███████▍  | 219/296 [00:51<00:18,  4.26it/s, v_num=0, train_loss=2.240]\n",
      "Epoch 2:  74%|███████▍  | 220/296 [00:51<00:17,  4.26it/s, v_num=0, train_loss=2.510]\n",
      "Epoch 2:  75%|███████▍  | 221/296 [00:51<00:17,  4.26it/s, v_num=0, train_loss=2.380]\n",
      "Epoch 2:  75%|███████▌  | 222/296 [00:52<00:17,  4.26it/s, v_num=0, train_loss=2.360]\n",
      "Epoch 2:  75%|███████▌  | 223/296 [00:52<00:17,  4.26it/s, v_num=0, train_loss=2.380]\n",
      "Epoch 2:  76%|███████▌  | 224/296 [00:52<00:16,  4.26it/s, v_num=0, train_loss=2.050]\n",
      "Epoch 2:  76%|███████▌  | 225/296 [00:52<00:16,  4.26it/s, v_num=0, train_loss=2.390]\n",
      "Epoch 2:  76%|███████▋  | 226/296 [00:53<00:16,  4.26it/s, v_num=0, train_loss=2.590]\n",
      "Epoch 2:  77%|███████▋  | 227/296 [00:53<00:16,  4.26it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 2:  77%|███████▋  | 228/296 [00:53<00:15,  4.27it/s, v_num=0, train_loss=1.900]\n",
      "Epoch 2:  77%|███████▋  | 229/296 [00:53<00:15,  4.27it/s, v_num=0, train_loss=2.520]\n",
      "Epoch 2:  78%|███████▊  | 230/296 [00:53<00:15,  4.27it/s, v_num=0, train_loss=2.220]\n",
      "Epoch 2:  78%|███████▊  | 231/296 [00:54<00:15,  4.27it/s, v_num=0, train_loss=2.680]\n",
      "Epoch 2:  78%|███████▊  | 232/296 [00:54<00:14,  4.27it/s, v_num=0, train_loss=2.290]\n",
      "Epoch 2:  79%|███████▊  | 233/296 [00:54<00:14,  4.27it/s, v_num=0, train_loss=2.710]\n",
      "Epoch 2:  79%|███████▉  | 234/296 [00:54<00:14,  4.27it/s, v_num=0, train_loss=2.340]\n",
      "Epoch 2:  79%|███████▉  | 235/296 [00:55<00:14,  4.25it/s, v_num=0, train_loss=2.310]\n",
      "Epoch 2:  80%|███████▉  | 236/296 [00:55<00:14,  4.25it/s, v_num=0, train_loss=1.980]\n",
      "Epoch 2:  80%|████████  | 237/296 [00:55<00:13,  4.25it/s, v_num=0, train_loss=2.780]\n",
      "Epoch 2:  80%|████████  | 238/296 [00:55<00:13,  4.25it/s, v_num=0, train_loss=2.450]\n",
      "Epoch 2:  81%|████████  | 239/296 [00:56<00:13,  4.25it/s, v_num=0, train_loss=1.950]\n",
      "Epoch 2:  81%|████████  | 240/296 [00:56<00:13,  4.25it/s, v_num=0, train_loss=2.460]\n",
      "Epoch 2:  81%|████████▏ | 241/296 [00:56<00:12,  4.26it/s, v_num=0, train_loss=2.440]\n",
      "Epoch 2:  82%|████████▏ | 242/296 [00:56<00:12,  4.26it/s, v_num=0, train_loss=2.510]\n",
      "Epoch 2:  82%|████████▏ | 243/296 [00:57<00:12,  4.26it/s, v_num=0, train_loss=2.510]\n",
      "Epoch 2:  82%|████████▏ | 244/296 [00:57<00:12,  4.26it/s, v_num=0, train_loss=2.040]\n",
      "Epoch 2:  83%|████████▎ | 245/296 [00:57<00:11,  4.26it/s, v_num=0, train_loss=2.120]\n",
      "Epoch 2:  83%|████████▎ | 246/296 [00:57<00:11,  4.26it/s, v_num=0, train_loss=2.560]\n",
      "Epoch 2:  83%|████████▎ | 247/296 [00:57<00:11,  4.26it/s, v_num=0, train_loss=2.310]\n",
      "Epoch 2:  84%|████████▍ | 248/296 [00:58<00:11,  4.26it/s, v_num=0, train_loss=2.490]\n",
      "Epoch 2:  84%|████████▍ | 249/296 [00:58<00:11,  4.26it/s, v_num=0, train_loss=2.350]\n",
      "Epoch 2:  84%|████████▍ | 250/296 [00:58<00:10,  4.26it/s, v_num=0, train_loss=2.500]\n",
      "Epoch 2:  85%|████████▍ | 251/296 [00:58<00:10,  4.26it/s, v_num=0, train_loss=2.280]\n",
      "Epoch 2:  85%|████████▌ | 252/296 [00:59<00:10,  4.26it/s, v_num=0, train_loss=2.360]\n",
      "Epoch 2:  85%|████████▌ | 253/296 [00:59<00:10,  4.26it/s, v_num=0, train_loss=2.500]\n",
      "Epoch 2:  86%|████████▌ | 254/296 [00:59<00:09,  4.26it/s, v_num=0, train_loss=2.360]\n",
      "Epoch 2:  86%|████████▌ | 255/296 [00:59<00:09,  4.26it/s, v_num=0, train_loss=2.540]\n",
      "Epoch 2:  86%|████████▋ | 256/296 [01:00<00:09,  4.26it/s, v_num=0, train_loss=2.190]\n",
      "Epoch 2:  87%|████████▋ | 257/296 [01:00<00:09,  4.26it/s, v_num=0, train_loss=2.050]\n",
      "Epoch 2:  87%|████████▋ | 258/296 [01:00<00:08,  4.27it/s, v_num=0, train_loss=2.560]\n",
      "Epoch 2:  88%|████████▊ | 259/296 [01:00<00:08,  4.27it/s, v_num=0, train_loss=2.500]\n",
      "Epoch 2:  88%|████████▊ | 260/296 [01:00<00:08,  4.26it/s, v_num=0, train_loss=2.380]\n",
      "Epoch 2:  88%|████████▊ | 261/296 [01:01<00:08,  4.27it/s, v_num=0, train_loss=2.400]\n",
      "Epoch 2:  89%|████████▊ | 262/296 [01:01<00:07,  4.27it/s, v_num=0, train_loss=2.440]\n",
      "Epoch 2:  89%|████████▉ | 263/296 [01:01<00:07,  4.27it/s, v_num=0, train_loss=2.330]\n",
      "Epoch 2:  89%|████████▉ | 264/296 [01:01<00:07,  4.27it/s, v_num=0, train_loss=2.590]\n",
      "Epoch 2:  90%|████████▉ | 265/296 [01:02<00:07,  4.27it/s, v_num=0, train_loss=2.480]\n",
      "Epoch 2:  90%|████████▉ | 266/296 [01:02<00:07,  4.26it/s, v_num=0, train_loss=2.180]\n",
      "Epoch 2:  90%|█████████ | 267/296 [01:02<00:06,  4.27it/s, v_num=0, train_loss=2.340]\n",
      "Epoch 2:  91%|█████████ | 268/296 [01:02<00:06,  4.27it/s, v_num=0, train_loss=2.510]\n",
      "Epoch 2:  91%|█████████ | 269/296 [01:03<00:06,  4.27it/s, v_num=0, train_loss=2.570]\n",
      "Epoch 2:  91%|█████████ | 270/296 [01:03<00:06,  4.27it/s, v_num=0, train_loss=2.460]\n",
      "Epoch 2:  92%|█████████▏| 271/296 [01:03<00:05,  4.27it/s, v_num=0, train_loss=2.550]\n",
      "Epoch 2:  92%|█████████▏| 272/296 [01:03<00:05,  4.27it/s, v_num=0, train_loss=2.490]\n",
      "Epoch 2:  92%|█████████▏| 273/296 [01:03<00:05,  4.27it/s, v_num=0, train_loss=2.390]\n",
      "Epoch 2:  93%|█████████▎| 274/296 [01:04<00:05,  4.27it/s, v_num=0, train_loss=2.420]\n",
      "Epoch 2:  93%|█████████▎| 275/296 [01:04<00:04,  4.27it/s, v_num=0, train_loss=2.430]\n",
      "Epoch 2:  93%|█████████▎| 276/296 [01:04<00:04,  4.27it/s, v_num=0, train_loss=3.080]\n",
      "Epoch 2:  94%|█████████▎| 277/296 [01:04<00:04,  4.27it/s, v_num=0, train_loss=2.520]\n",
      "Epoch 2:  94%|█████████▍| 278/296 [01:05<00:04,  4.27it/s, v_num=0, train_loss=2.240]\n",
      "Epoch 2:  94%|█████████▍| 279/296 [01:05<00:03,  4.27it/s, v_num=0, train_loss=2.680]\n",
      "Epoch 2:  95%|█████████▍| 280/296 [01:05<00:03,  4.27it/s, v_num=0, train_loss=2.170]\n",
      "Epoch 2:  95%|█████████▍| 281/296 [01:05<00:03,  4.27it/s, v_num=0, train_loss=2.350]\n",
      "Epoch 2:  95%|█████████▌| 282/296 [01:06<00:03,  4.27it/s, v_num=0, train_loss=2.340]\n",
      "Epoch 2:  96%|█████████▌| 283/296 [01:06<00:03,  4.27it/s, v_num=0, train_loss=2.490]\n",
      "Epoch 2:  96%|█████████▌| 284/296 [01:06<00:02,  4.27it/s, v_num=0, train_loss=2.450]\n",
      "Epoch 2:  96%|█████████▋| 285/296 [01:06<00:02,  4.27it/s, v_num=0, train_loss=2.590]\n",
      "Epoch 2:  97%|█████████▋| 286/296 [01:06<00:02,  4.27it/s, v_num=0, train_loss=2.520]\n",
      "Epoch 2:  97%|█████████▋| 287/296 [01:07<00:02,  4.27it/s, v_num=0, train_loss=2.120]\n",
      "Epoch 2:  97%|█████████▋| 288/296 [01:07<00:01,  4.27it/s, v_num=0, train_loss=2.730]\n",
      "Epoch 2:  98%|█████████▊| 289/296 [01:07<00:01,  4.28it/s, v_num=0, train_loss=2.640]\n",
      "Epoch 2:  98%|█████████▊| 290/296 [01:07<00:01,  4.28it/s, v_num=0, train_loss=2.600]\n",
      "Epoch 2:  98%|█████████▊| 291/296 [01:08<00:01,  4.28it/s, v_num=0, train_loss=2.730]\n",
      "Epoch 2:  99%|█████████▊| 292/296 [01:08<00:00,  4.28it/s, v_num=0, train_loss=2.540]\n",
      "Epoch 2:  99%|█████████▉| 293/296 [01:08<00:00,  4.28it/s, v_num=0, train_loss=2.040]\n",
      "Epoch 2:  99%|█████████▉| 294/296 [01:08<00:00,  4.28it/s, v_num=0, train_loss=2.080]\n",
      "Epoch 2: 100%|█████████▉| 295/296 [01:08<00:00,  4.28it/s, v_num=0, train_loss=2.710]\n",
      "Epoch 2: 100%|██████████| 296/296 [01:09<00:00,  4.28it/s, v_num=0, train_loss=2.670]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4156085)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/davinci-1/home/abeatini/ray_results/TorchTrainer_2025-06-26_19-01-27/TorchTrainer_32cee_00000_0_2025-06-26_19-01-27/checkpoint_000002)\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 296/296 [01:09<00:00,  4.24it/s, v_num=0, train_loss=2.670]\n",
      "Epoch 2: 100%|██████████| 296/296 [01:10<00:00,  4.22it/s, v_num=0, train_loss=2.670]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=246798, ip=10.141.1.44)\u001b[0m 2025-06-26 19:05:58,840 - INFO - `Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "ray.init(address=\"10.141.1.24:6379\")\n",
    "\n",
    "if ray.is_initialized():\n",
    "    print(\"RAy already up and running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a56ee0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object_store_memory': 318480340991.0,\n",
       " 'accelerator_type:A100': 2.0,\n",
       " 'node:__internal_head__': 1.0,\n",
       " 'memory': 743120795649.0,\n",
       " 'GPU': 8.0,\n",
       " 'CPU': 96.0,\n",
       " 'node:10.141.1.24': 1.0,\n",
       " 'node:10.141.1.44': 1.0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b15fe80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-26 18:21:42,475] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 18:21:42,789 - INFO - gcc -pthread -B /davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /davinci-1/home/abeatini/.conda/envs/shallow/include -fPIC -O2 -isystem /davinci-1/home/abeatini/.conda/envs/shallow/include -fPIC -c /tmp/tmp4pe4kps9/test.c -o /tmp/tmp4pe4kps9/test.o\n",
      "2025-06-26 18:21:42,810 - INFO - gcc -pthread -B /davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat /tmp/tmp4pe4kps9/test.o -laio -o /tmp/tmp4pe4kps9/a.out\n",
      "/davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "2025-06-26 18:21:43,418 - INFO - gcc -pthread -B /davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /davinci-1/home/abeatini/.conda/envs/shallow/include -fPIC -O2 -isystem /davinci-1/home/abeatini/.conda/envs/shallow/include -fPIC -c /tmp/tmp14lllmos/test.c -o /tmp/tmp14lllmos/test.o\n",
      "2025-06-26 18:21:43,439 - INFO - gcc -pthread -B /davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat /tmp/tmp14lllmos/test.o -L/cm/shared/apps/cuda12.1/toolkit/12.1.1 -L/cm/shared/apps/cuda12.1/toolkit/12.1.1/lib64 -lcufile -o /tmp/tmp14lllmos/a.out\n",
      "/davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat/ld: warning: libm.so.6, needed by /cm/shared/apps/cuda12.1/toolkit/12.1.1/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat/ld: /cm/shared/apps/cuda12.1/toolkit/12.1.1/lib64/libcufile.so: undefined reference to `log2f@GLIBC_2.2.5'\n",
      "/davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat/ld: /cm/local/apps/gcc/11.2.0/lib64/libstdc++.so.6: undefined reference to `fesetround@GLIBC_2.2.5'\n",
      "/davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat/ld: /cm/shared/apps/cuda12.1/toolkit/12.1.1/lib64/libcufile.so: undefined reference to `dlopen'\n",
      "/davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat/ld: /cm/local/apps/gcc/11.2.0/lib64/libstdc++.so.6: undefined reference to `fegetround@GLIBC_2.2.5'\n",
      "/davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat/ld: /cm/shared/apps/cuda12.1/toolkit/12.1.1/lib64/libcufile.so: undefined reference to `dlclose'\n",
      "/davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat/ld: /cm/shared/apps/cuda12.1/toolkit/12.1.1/lib64/libcufile.so: undefined reference to `dlerror'\n",
      "/davinci-1/home/abeatini/.conda/envs/shallow/compiler_compat/ld: /cm/shared/apps/cuda12.1/toolkit/12.1.1/lib64/libcufile.so: undefined reference to `dlsym'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "# Ray-aware DeepSpeed ZeRO-3 strategy\n",
    "import json\n",
    "from pathlib import Path\n",
    "config_path = Path(\"/davinci-1/home/abeatini/pycharmProjects/shallowMind/config/ds_config.json\")\n",
    "\n",
    "# Read the file’s contents and turn it into a Python dict\n",
    "with config_path.open() as f:\n",
    "    ds_config = json.load(f)          # <-- use json.load, not json.loads\n",
    "strategy = RayDeepSpeedStrategy(ds_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d59cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cfg = {\n",
    "    \"train_micro_batch_size_per_gpu\": 4,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"fp16\": {\"enabled\": True},\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_optimizer\": {\"device\": \"cpu\", \"pin_memory\": True},\n",
    "        \"offload_param\":    {\"device\": \"cpu\", \"pin_memory\": True},\n",
    "        \"overlap_comm\": True,\n",
    "        \"contiguous_gradients\": True,\n",
    "        \"reduce_bucket_size\":            500_000_000,\n",
    "        \"stage3_prefetch_bucket_size\":   500_000_000,\n",
    "        \"stage3_param_persistence_threshold\": 1_000_000\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Ray-aware DeepSpeed ZeRO-3 strategy\n",
    "strategy = RayDeepSpeedStrategy(stage=3, config=ds_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 19:01:27,363\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAy already up and running\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:01:27 (running for 00:00:00.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:01:32 (running for 00:00:05.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:01:37 (running for 00:00:10.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:01:42 (running for 00:00:15.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:01:47 (running for 00:00:20.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:01:52 (running for 00:00:25.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:01:57 (running for 00:00:30.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:02:02 (running for 00:00:35.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:02:07 (running for 00:00:40.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:02:12 (running for 00:00:45.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:02:17 (running for 00:00:50.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:02:22 (running for 00:00:55.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:02:27 (running for 00:01:00.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:02:32 (running for 00:01:05.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:02:37 (running for 00:01:10.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:02:42 (running for 00:01:15.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:02:47 (running for 00:01:20.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:02:52 (running for 00:01:25.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:02:57 (running for 00:01:30.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:03:02 (running for 00:01:35.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:03:07 (running for 00:01:40.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:03:12 (running for 00:01:45.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:03:17 (running for 00:01:50.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:03:22 (running for 00:01:55.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:03:27 (running for 00:02:00.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:03:32 (running for 00:02:05.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:03:37 (running for 00:02:10.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:03:42 (running for 00:02:15.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:03:47 (running for 00:02:20.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:03:52 (running for 00:02:25.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:03:58 (running for 00:02:30.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:04:03 (running for 00:02:35.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:04:08 (running for 00:02:40.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:04:13 (running for 00:02:45.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:04:18 (running for 00:02:50.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:04:23 (running for 00:02:55.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:04:28 (running for 00:03:00.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:04:33 (running for 00:03:05.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:04:38 (running for 00:03:10.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:04:43 (running for 00:03:15.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 19:04:48,292\tERROR checkpoint_manager.py:144 -- Result dict has no key: val_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['train_loss', 'epoch', 'step', 'timestamp', 'checkpoint_dir_name', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore']\n",
      "2025-06-26 19:04:48,292\tERROR checkpoint_manager.py:144 -- Result dict has no key: val_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['train_loss', 'epoch', 'step', 'timestamp', 'checkpoint_dir_name', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-26 19:04:48 (running for 00:03:20.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:04:53 (running for 00:03:25.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:04:58 (running for 00:03:30.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:05:03 (running for 00:03:35.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:05:08 (running for 00:03:40.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:05:13 (running for 00:03:45.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:05:18 (running for 00:03:50.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:05:23 (running for 00:03:55.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:05:28 (running for 00:04:00.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:05:33 (running for 00:04:05.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:05:38 (running for 00:04:10.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:05:43 (running for 00:04:15.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:05:48 (running for 00:04:20.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-26 19:05:53 (running for 00:04:26.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 19:05:58,478\tERROR checkpoint_manager.py:144 -- Result dict has no key: val_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['train_loss', 'epoch', 'step', 'timestamp', 'checkpoint_dir_name', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore']\n",
      "2025-06-26 19:05:58,479\tERROR checkpoint_manager.py:144 -- Result dict has no key: val_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['train_loss', 'epoch', 'step', 'timestamp', 'checkpoint_dir_name', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore']\n",
      "2025-06-26 19:05:58,480\tERROR checkpoint_manager.py:144 -- Result dict has no key: val_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['train_loss', 'epoch', 'step', 'timestamp', 'checkpoint_dir_name', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore']\n",
      "2025-06-26 19:05:58,480\tERROR checkpoint_manager.py:144 -- Result dict has no key: val_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['train_loss', 'epoch', 'step', 'timestamp', 'checkpoint_dir_name', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-26 19:05:58 (running for 00:04:31.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 19:06:01,186\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/davinci-1/home/abeatini/ray_results/TorchTrainer_2025-06-26_19-01-27' in 0.0045s.\n",
      "2025-06-26 19:06:01,189\tINFO tune.py:1041 -- Total run time: 273.83 seconds (273.81 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-26 19:06:01 (running for 00:04:33.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 17.0/96 CPUs, 8.0/8 GPUs (0.0/2.0 accelerator_type:A100)\n",
      "Result logdir: /var/tmp/pbs.1874768.davinci-mgt01/ray/session_2025-06-26_17-23-15_385852_3806738/artifacts/2025-06-26_19-01-27/TorchTrainer_2025-06-26_19-01-27/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n",
      "Result(\n",
      "  metrics={'train_loss': 2.669545888900757, 'epoch': 2, 'step': 888},\n",
      "  path='/davinci-1/home/abeatini/ray_results/TorchTrainer_2025-06-26_19-01-27/TorchTrainer_32cee_00000_0_2025-06-26_19-01-27',\n",
      "  filesystem='local',\n",
      "  checkpoint=Checkpoint(filesystem=local, path=/davinci-1/home/abeatini/ray_results/TorchTrainer_2025-06-26_19-01-27/TorchTrainer_32cee_00000_0_2025-06-26_19-01-27/checkpoint_000002)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# train_llm_ray_lightning.py\n",
    "import torch\n",
    "import pytorch_lightning as pl                  # new import style in Lightning ≥2.0\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from src.data.data_manager import LightningDataModule\n",
    "\n",
    "# --- Ray Train imports -------------------------------------------------------\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, WandbLogger\n",
    "from ray.train import ScalingConfig, RunConfig, CheckpointConfig\n",
    "from ray.train.torch import TorchTrainer        # replaces RayLightningTrainer\n",
    "from ray.train.lightning import (               # V2 Lightning helpers\n",
    "    RayDeepSpeedStrategy,                       # Ray-compatible ZeRO-3\n",
    "    RayLightningEnvironment,                    # cluster-aware env plugin\n",
    "    RayTrainReportCallback,                     # metrics/ckpt reporter\n",
    "    prepare_trainer,                            # patches the PL trainer\n",
    ")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import ray\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class LLMModel(pl.LightningModule):\n",
    "    def __init__(self, model_name, learning_rate=1e-5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        #default is crossentropy\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None, **kwargs):\n",
    "        out = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=input_ids,\n",
    "        )\n",
    "        return out.loss\n",
    "\n",
    "    def training_step(self, batch,  _):\n",
    "        loss = self(**batch)\n",
    "        self.log(\"loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # with Deepspeed You are using ZeRO-Offload with a client provided\n",
    "        #  optimizer (<class 'torch.optim.adamw.AdamW'>) which in most cases will yield poor performance.\n",
    "        #  Please either use deepspeed.ops.adam.DeepSpeedCPUAdam or set an optimizer in your ds-config \n",
    "        # return torch.optim.AdamW(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return None\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    \"\"\"Executed once per Ray worker.\"\"\"\n",
    "    model_name = config.get(\"model_name\", \"gpt2\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    datamodule = LightningDataModule(\n",
    "        tokenizer=tokenizer,\n",
    "        dataset_configs={\"wikitext\": {}},\n",
    "        batch_size=2,\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "    model = LLMModel(model_name=model_name)\n",
    "\n",
    "    ds_cfg_gpu = {\n",
    "        # ---- batching ----------------------------------------------------------\n",
    "        \"train_micro_batch_size_per_gpu\": 4,      # fits comfortably on an A100\n",
    "         #\"gradient_accumulation_steps\": 2,         # 4 × 2 × 8 GPUs  = 64/global step\n",
    "        \"gradient_clipping\": 1.0,\n",
    "\n",
    "        # ---- numerics ----------------------------------------------------------\n",
    "        \"fp16\": { \"enabled\": True },              # or switch to \"bf16\":{…}\n",
    "\n",
    "        # ---- ZeRO ----------------------------------------------------------------\n",
    "        \"zero_optimization\": {\n",
    "            \"stage\": 3,\n",
    "            \"overlap_comm\": True,\n",
    "            \"contiguous_gradients\": True,\n",
    "            \"reduce_bucket_size\":            500_000_000,\n",
    "            \"stage3_prefetch_bucket_size\":   500_000_000,\n",
    "            \"stage3_param_persistence_threshold\": 1_000_000\n",
    "        },\n",
    "\n",
    "        # ---- optimizer created by DeepSpeed (GPU AdamW fused) -------------------\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"AdamW\",\n",
    "            \"params\": {\n",
    "                \"lr\": 1e-5,\n",
    "                \"betas\": [0.9, 0.999],\n",
    "                \"eps\": 1e-8,\n",
    "                \"weight_decay\": 0.01\n",
    "            }\n",
    "        },\n",
    "\n",
    "        # ---- optional LR scheduler ---------------------------------------------\n",
    "        \"scheduler\": {\n",
    "            \"type\": \"WarmupDecayLR\",\n",
    "            \"params\": {\n",
    "                \"total_num_steps\": 10_000,\n",
    "                \"warmup_num_steps\": 1_000,\n",
    "                \"warmup_min_lr\": 0\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Ray-aware DeepSpeed ZeRO-3 strategy\n",
    "    strategy = RayDeepSpeedStrategy(stage=3, config=ds_cfg_gpu)\n",
    "    \n",
    "    tb_logger = TensorBoardLogger(save_dir=\"tb_logs\", name=\"run1\")\n",
    "\n",
    "    # Standard Lightning trainer plus Ray plugins/callback\n",
    "    pl_trainer = pl.Trainer(\n",
    "        strategy=strategy,\n",
    "        accelerator=\"auto\",           # Ray sets CUDA_VISIBLE_DEVICES per worker\n",
    "        devices=\"auto\",\n",
    "        precision=\"16-mixed\",\n",
    "        max_epochs=3,\n",
    "        plugins=[RayLightningEnvironment()],\n",
    "        callbacks=[RayTrainReportCallback()],\n",
    "        log_every_n_steps=5,\n",
    "        logger= tb_logger\n",
    "    )\n",
    "\n",
    "    # Patch the trainer for Ray & validate the config\n",
    "    pl_trainer = prepare_trainer(pl_trainer)\n",
    "\n",
    "    # Launch training\n",
    "    pl_trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "def init_ray():\n",
    "    if ray.is_initialized():\n",
    "        print(\"RAy already up and running\")\n",
    "        return\n",
    "    else:\n",
    "        ray.init(address=\"10.141.1.24:6379\")\n",
    "        if ray.is_initialized():\n",
    "            print(\"RAy already up and running\")\n",
    "        else: \n",
    "            raise Exception\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    init_ray()\n",
    "    scaling = ScalingConfig(\n",
    "        num_workers=8,               # 8 GPUs total\n",
    "        use_gpu=True,\n",
    "        resources_per_worker={\"CPU\": 2, \"GPU\": 1},\n",
    "        placement_strategy=\"SPREAD\"\n",
    "    )\n",
    "\n",
    "    trainer = TorchTrainer(          # <- NEW\n",
    "        train_loop_per_worker=train_loop_per_worker,\n",
    "        scaling_config=scaling,\n",
    "        run_config=RunConfig(\n",
    "            checkpoint_config=CheckpointConfig(\n",
    "                num_to_keep=3,\n",
    "                checkpoint_score_attribute=\"val_loss\",\n",
    "                checkpoint_score_order=\"min\",\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    result = trainer.fit()\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shallow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
